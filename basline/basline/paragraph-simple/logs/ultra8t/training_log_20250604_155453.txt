Paragraph-Simple 训练日志
数据集: ultra8t
训练参数: {'train_dataset': 'ultra8t', 'test_dataset': 'ssram+digtime+timing_ctrl+array_128_32_8t', 'task': 'regression', 'max_dist': 350, 'lr': 5e-05, 'num_gnn_layers': 4, 'num_head_layers': 2, 'hid_dim': 64, 'dropout': 0.0, 'use_bn': 0, 'act_fn': 'relu', 'src_dst_agg': 'concat', 'num_hops': 4, 'to_undirected': 1, 'train_sample_rate': 0.1, 'test_sample_rate': 1.0, 'use_ensemble': 0, 'num_ensemble': 3, 'ensemble_thresholds': '0.33,0.66'}

Epoch 1/200 - 训练: loss=0.016500 mae=0.097400 mse=0.016500 rmse=0.016500 r2=0.354400 
Epoch 1/200 - 验证: loss=0.015200 mae=0.092900 mse=0.015200 rmse=0.015200 r2=0.406200 
【新的最佳模型！】Epoch 1
测试集 ssram: loss=0.014700 mae=0.090500 mse=0.014700 rmse=0.014700 r2=0.322600 
测试集 digtime: loss=0.018700 mae=0.109000 mse=0.018700 rmse=0.018700 r2=0.139700 
测试集 timing_ctrl: loss=0.025300 mae=0.140800 mse=0.025300 rmse=0.025300 r2=0.199300 
测试集 array_128_32_8t: loss=0.012000 mae=0.073800 mse=0.012000 rmse=0.012000 r2=0.405900 

Epoch 2/200 - 训练: loss=0.015600 mae=0.093500 mse=0.015600 rmse=0.015600 r2=0.390600 
Epoch 2/200 - 验证: loss=0.015200 mae=0.090400 mse=0.015200 rmse=0.015200 r2=0.408300 
【新的最佳模型！】Epoch 2
测试集 ssram: loss=0.014300 mae=0.088300 mse=0.014300 rmse=0.014300 r2=0.340600 
测试集 digtime: loss=0.016200 mae=0.102700 mse=0.016200 rmse=0.016200 r2=0.252800 
测试集 timing_ctrl: loss=0.021500 mae=0.125600 mse=0.021500 rmse=0.021500 r2=0.319300 
测试集 array_128_32_8t: loss=0.012100 mae=0.075100 mse=0.012100 rmse=0.012100 r2=0.400800 

Epoch 3/200 - 训练: loss=0.015400 mae=0.092700 mse=0.015400 rmse=0.015400 r2=0.397600 
Epoch 3/200 - 验证: loss=0.015200 mae=0.090900 mse=0.015200 rmse=0.015200 r2=0.405700 
Epoch 4/200 - 训练: loss=0.015300 mae=0.092300 mse=0.015300 rmse=0.015300 r2=0.401500 
Epoch 4/200 - 验证: loss=0.015100 mae=0.089800 mse=0.015100 rmse=0.015100 r2=0.410400 
【新的最佳模型！】Epoch 4
测试集 ssram: loss=0.013600 mae=0.085800 mse=0.013600 rmse=0.013600 r2=0.372700 
测试集 digtime: loss=0.019600 mae=0.105500 mse=0.019600 rmse=0.019600 r2=0.097400 
测试集 timing_ctrl: loss=0.019400 mae=0.117300 mse=0.019400 rmse=0.019400 r2=0.385900 
测试集 array_128_32_8t: loss=0.011500 mae=0.072300 mse=0.011500 rmse=0.011500 r2=0.426500 

Epoch 5/200 - 训练: loss=0.015200 mae=0.092000 mse=0.015200 rmse=0.015200 r2=0.404400 
Epoch 5/200 - 验证: loss=0.015300 mae=0.091100 mse=0.015300 rmse=0.015300 r2=0.402100 
Epoch 6/200 - 训练: loss=0.015200 mae=0.091800 mse=0.015200 rmse=0.015200 r2=0.406200 
Epoch 6/200 - 验证: loss=0.015000 mae=0.091200 mse=0.015000 rmse=0.015000 r2=0.415000 
【新的最佳模型！】Epoch 6
测试集 ssram: loss=0.014300 mae=0.089500 mse=0.014300 rmse=0.014300 r2=0.342400 
测试集 digtime: loss=0.020300 mae=0.108800 mse=0.020300 rmse=0.020300 r2=0.064800 
测试集 timing_ctrl: loss=0.021800 mae=0.127700 mse=0.021800 rmse=0.021800 r2=0.309900 
测试集 array_128_32_8t: loss=0.011400 mae=0.074300 mse=0.011400 rmse=0.011400 r2=0.433900 

Epoch 7/200 - 训练: loss=0.015200 mae=0.091600 mse=0.015200 rmse=0.015200 r2=0.407500 
Epoch 7/200 - 验证: loss=0.016800 mae=0.102800 mse=0.016800 rmse=0.016800 r2=0.344300 
Epoch 8/200 - 训练: loss=0.015100 mae=0.091500 mse=0.015100 rmse=0.015100 r2=0.409000 
Epoch 8/200 - 验证: loss=0.014900 mae=0.090300 mse=0.014900 rmse=0.014900 r2=0.416600 
【新的最佳模型！】Epoch 8
测试集 ssram: loss=0.014000 mae=0.087700 mse=0.014000 rmse=0.014000 r2=0.357300 
测试集 digtime: loss=0.020200 mae=0.108200 mse=0.020200 rmse=0.020200 r2=0.067300 
测试集 timing_ctrl: loss=0.020600 mae=0.123600 mse=0.020600 rmse=0.020600 r2=0.350500 
测试集 array_128_32_8t: loss=0.011300 mae=0.072200 mse=0.011300 rmse=0.011300 r2=0.438000 

Epoch 9/200 - 训练: loss=0.015100 mae=0.091500 mse=0.015100 rmse=0.015100 r2=0.409500 
Epoch 9/200 - 验证: loss=0.015900 mae=0.097200 mse=0.015900 rmse=0.015900 r2=0.379700 
Epoch 10/200 - 训练: loss=0.015100 mae=0.091400 mse=0.015100 rmse=0.015100 r2=0.410300 
Epoch 10/200 - 验证: loss=0.015100 mae=0.089900 mse=0.015100 rmse=0.015100 r2=0.412300 
Epoch 11/200 - 训练: loss=0.015100 mae=0.091300 mse=0.015100 rmse=0.015100 r2=0.411000 
Epoch 11/200 - 验证: loss=0.015100 mae=0.093200 mse=0.015100 rmse=0.015100 r2=0.410800 
Epoch 12/200 - 训练: loss=0.015100 mae=0.091200 mse=0.015100 rmse=0.015100 r2=0.411600 
Epoch 12/200 - 验证: loss=0.015000 mae=0.089700 mse=0.015000 rmse=0.015000 r2=0.415800 
Epoch 13/200 - 训练: loss=0.015000 mae=0.091100 mse=0.015000 rmse=0.015000 r2=0.412700 
Epoch 13/200 - 验证: loss=0.015000 mae=0.092100 mse=0.015000 rmse=0.015000 r2=0.413300 
Epoch 14/200 - 训练: loss=0.015000 mae=0.091000 mse=0.015000 rmse=0.015000 r2=0.413300 
Epoch 14/200 - 验证: loss=0.015000 mae=0.092400 mse=0.015000 rmse=0.015000 r2=0.413200 
Epoch 15/200 - 训练: loss=0.015000 mae=0.090900 mse=0.015000 rmse=0.015000 r2=0.414700 
Epoch 15/200 - 验证: loss=0.015100 mae=0.092500 mse=0.015100 rmse=0.015100 r2=0.412200 
Epoch 16/200 - 训练: loss=0.015000 mae=0.090800 mse=0.015000 rmse=0.015000 r2=0.415500 
Epoch 16/200 - 验证: loss=0.015500 mae=0.095600 mse=0.015500 rmse=0.015500 r2=0.394800 
Epoch 17/200 - 训练: loss=0.014900 mae=0.090700 mse=0.014900 rmse=0.014900 r2=0.416300 
Epoch 17/200 - 验证: loss=0.016800 mae=0.097000 mse=0.016800 rmse=0.016800 r2=0.346000 
Epoch 18/200 - 训练: loss=0.014900 mae=0.090600 mse=0.014900 rmse=0.014900 r2=0.418100 
Epoch 18/200 - 验证: loss=0.014800 mae=0.089800 mse=0.014800 rmse=0.014800 r2=0.424000 
【新的最佳模型！】Epoch 18
测试集 ssram: loss=0.014100 mae=0.088400 mse=0.014100 rmse=0.014100 r2=0.349800 
测试集 digtime: loss=0.024800 mae=0.125700 mse=0.024800 rmse=0.024800 r2=-0.143700 
测试集 timing_ctrl: loss=0.020300 mae=0.121600 mse=0.020300 rmse=0.020300 r2=0.358400 
测试集 array_128_32_8t: loss=0.011600 mae=0.076400 mse=0.011600 rmse=0.011600 r2=0.424900 

Epoch 19/200 - 训练: loss=0.014900 mae=0.090400 mse=0.014900 rmse=0.014900 r2=0.419500 
Epoch 19/200 - 验证: loss=0.015700 mae=0.098100 mse=0.015700 rmse=0.015700 r2=0.386100 
Epoch 20/200 - 训练: loss=0.014800 mae=0.090200 mse=0.014800 rmse=0.014800 r2=0.420800 
Epoch 20/200 - 验证: loss=0.015300 mae=0.095300 mse=0.015300 rmse=0.015300 r2=0.402600 
Epoch 21/200 - 训练: loss=0.014800 mae=0.090000 mse=0.014800 rmse=0.014800 r2=0.422100 
Epoch 21/200 - 验证: loss=0.015500 mae=0.091400 mse=0.015500 rmse=0.015500 r2=0.396800 
