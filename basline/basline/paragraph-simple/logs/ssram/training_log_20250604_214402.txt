Paragraph-Simple 训练日志
数据集: ssram
训练参数: {'train_dataset': 'ssram', 'test_dataset': 'digtime+timing_ctrl+array_128_32_8t', 'task': 'regression', 'max_dist': 350, 'lr': 5e-05, 'num_gnn_layers': 4, 'num_head_layers': 2, 'hid_dim': 64, 'dropout': 0.3, 'use_bn': 0, 'act_fn': 'relu', 'src_dst_agg': 'concat', 'num_hops': 4, 'to_undirected': 1, 'train_sample_rate': 0.1, 'test_sample_rate': 1.0, 'use_ensemble': 0, 'num_ensemble': 3, 'ensemble_thresholds': '0.33,0.66'}

Epoch 1/200 - 训练: loss=0.086800 mae=0.230800 mse=0.086800 rmse=0.086800 r2=-2.949500 
Epoch 1/200 - 验证: loss=0.137900 mae=0.352400 mse=0.137900 rmse=0.137900 r2=-5.491400 
【新的最佳模型！】Epoch 1
测试集 digtime: loss=0.133000 mae=0.342500 mse=0.133000 rmse=0.133000 r2=-5.130400 
测试集 timing_ctrl: loss=0.184000 mae=0.412300 mse=0.184000 rmse=0.184000 r2=-4.813500 
测试集 array_128_32_8t: loss=0.130700 mae=0.344100 mse=0.130700 rmse=0.130700 r2=-5.492200 

Epoch 2/200 - 训练: loss=0.039900 mae=0.158700 mse=0.039900 rmse=0.039900 r2=-0.815400 
Epoch 2/200 - 验证: loss=0.108000 mae=0.310000 mse=0.108000 rmse=0.108000 r2=-4.080800 
【新的最佳模型！】Epoch 2
测试集 digtime: loss=0.100300 mae=0.294000 mse=0.100300 rmse=0.100300 r2=-3.624100 
测试集 timing_ctrl: loss=0.148400 mae=0.368200 mse=0.148400 rmse=0.148400 r2=-3.686800 
测试集 array_128_32_8t: loss=0.103400 mae=0.304400 mse=0.103400 rmse=0.103400 r2=-4.135000 

Epoch 3/200 - 训练: loss=0.032400 mae=0.142700 mse=0.032400 rmse=0.032400 r2=-0.475700 
Epoch 3/200 - 验证: loss=0.090000 mae=0.282100 mse=0.090000 rmse=0.090000 r2=-3.234100 
【新的最佳模型！】Epoch 3
测试集 digtime: loss=0.083100 mae=0.266200 mse=0.083100 rmse=0.083100 r2=-2.831600 
测试集 timing_ctrl: loss=0.129000 mae=0.341000 mse=0.129000 rmse=0.129000 r2=-3.074900 
测试集 array_128_32_8t: loss=0.085400 mae=0.277100 mse=0.085400 rmse=0.085400 r2=-3.242100 

Epoch 4/200 - 训练: loss=0.027500 mae=0.130200 mse=0.027500 rmse=0.027500 r2=-0.252000 
Epoch 4/200 - 验证: loss=0.084400 mae=0.272900 mse=0.084400 rmse=0.084400 r2=-2.971700 
【新的最佳模型！】Epoch 4
测试集 digtime: loss=0.079300 mae=0.260900 mse=0.079300 rmse=0.079300 r2=-2.656800 
测试集 timing_ctrl: loss=0.126600 mae=0.333700 mse=0.126600 rmse=0.126600 r2=-2.998500 
测试集 array_128_32_8t: loss=0.080500 mae=0.269800 mse=0.080500 rmse=0.080500 r2=-3.000000 

Epoch 5/200 - 训练: loss=0.024200 mae=0.121600 mse=0.024200 rmse=0.024200 r2=-0.100500 
Epoch 5/200 - 验证: loss=0.078200 mae=0.261600 mse=0.078200 rmse=0.078200 r2=-2.679900 
【新的最佳模型！】Epoch 5
测试集 digtime: loss=0.074600 mae=0.252100 mse=0.074600 rmse=0.074600 r2=-2.440800 
测试集 timing_ctrl: loss=0.119700 mae=0.324600 mse=0.119700 rmse=0.119700 r2=-2.780500 
测试集 array_128_32_8t: loss=0.074200 mae=0.258000 mse=0.074200 rmse=0.074200 r2=-2.683800 

Epoch 6/200 - 训练: loss=0.022200 mae=0.116500 mse=0.022200 rmse=0.022200 r2=-0.010200 
Epoch 6/200 - 验证: loss=0.071400 mae=0.248900 mse=0.071400 rmse=0.071400 r2=-2.362100 
【新的最佳模型！】Epoch 6
测试集 digtime: loss=0.067900 mae=0.238800 mse=0.067900 rmse=0.067900 r2=-2.128600 
测试集 timing_ctrl: loss=0.111000 mae=0.312400 mse=0.111000 rmse=0.111000 r2=-2.506700 
测试集 array_128_32_8t: loss=0.067600 mae=0.245300 mse=0.067600 rmse=0.067600 r2=-2.355700 

Epoch 7/200 - 训练: loss=0.020500 mae=0.111900 mse=0.020500 rmse=0.020500 r2=0.065300 
Epoch 7/200 - 验证: loss=0.066200 mae=0.236400 mse=0.066200 rmse=0.066200 r2=-2.118000 
【新的最佳模型！】Epoch 7
测试集 digtime: loss=0.062800 mae=0.226800 mse=0.062800 rmse=0.062800 r2=-1.892700 
测试集 timing_ctrl: loss=0.106000 mae=0.302300 mse=0.106000 rmse=0.106000 r2=-2.348100 
测试集 array_128_32_8t: loss=0.062700 mae=0.233600 mse=0.062700 rmse=0.062700 r2=-2.113000 

Epoch 8/200 - 训练: loss=0.019700 mae=0.108800 mse=0.019700 rmse=0.019700 r2=0.103800 
Epoch 8/200 - 验证: loss=0.063100 mae=0.229700 mse=0.063100 rmse=0.063100 r2=-1.968800 
【新的最佳模型！】Epoch 8
测试集 digtime: loss=0.059400 mae=0.219300 mse=0.059400 rmse=0.059400 r2=-1.738300 
测试集 timing_ctrl: loss=0.101300 mae=0.295500 mse=0.101300 rmse=0.101300 r2=-2.198800 
测试集 array_128_32_8t: loss=0.059500 mae=0.226500 mse=0.059500 rmse=0.059500 r2=-1.957800 

Epoch 9/200 - 训练: loss=0.019100 mae=0.106500 mse=0.019100 rmse=0.019100 r2=0.130600 
Epoch 9/200 - 验证: loss=0.064300 mae=0.228900 mse=0.064300 rmse=0.064300 r2=-2.024200 
Epoch 10/200 - 训练: loss=0.018500 mae=0.105400 mse=0.018500 rmse=0.018500 r2=0.159700 
Epoch 10/200 - 验证: loss=0.057800 mae=0.217100 mse=0.057800 rmse=0.057800 r2=-1.718600 
【新的最佳模型！】Epoch 10
测试集 digtime: loss=0.054700 mae=0.207500 mse=0.054700 rmse=0.054700 r2=-1.522000 
测试集 timing_ctrl: loss=0.095000 mae=0.284300 mse=0.095000 rmse=0.095000 r2=-2.000100 
测试集 array_128_32_8t: loss=0.054300 mae=0.213600 mse=0.054300 rmse=0.054300 r2=-1.699300 

Epoch 11/200 - 训练: loss=0.017800 mae=0.102200 mse=0.017800 rmse=0.017800 r2=0.188100 
Epoch 11/200 - 验证: loss=0.052200 mae=0.207400 mse=0.052200 rmse=0.052200 r2=-1.456400 
【新的最佳模型！】Epoch 11
测试集 digtime: loss=0.049500 mae=0.198100 mse=0.049500 rmse=0.049500 r2=-1.280500 
测试集 timing_ctrl: loss=0.087400 mae=0.273800 mse=0.087400 rmse=0.087400 r2=-1.760900 
测试集 array_128_32_8t: loss=0.048800 mae=0.203900 mse=0.048800 rmse=0.048800 r2=-1.423000 

Epoch 12/200 - 训练: loss=0.017600 mae=0.101700 mse=0.017600 rmse=0.017600 r2=0.199800 
Epoch 12/200 - 验证: loss=0.046600 mae=0.192100 mse=0.046600 rmse=0.046600 r2=-1.191500 
【新的最佳模型！】Epoch 12
测试集 digtime: loss=0.044800 mae=0.185300 mse=0.044800 rmse=0.044800 r2=-1.064300 
测试集 timing_ctrl: loss=0.081300 mae=0.261400 mse=0.081300 rmse=0.081300 r2=-1.568800 
测试集 array_128_32_8t: loss=0.043400 mae=0.189200 mse=0.043400 rmse=0.043400 r2=-1.156700 

Epoch 13/200 - 训练: loss=0.017200 mae=0.100300 mse=0.017200 rmse=0.017200 r2=0.216600 
Epoch 13/200 - 验证: loss=0.052500 mae=0.205000 mse=0.052500 rmse=0.052500 r2=-1.469800 
Epoch 14/200 - 训练: loss=0.016900 mae=0.099700 mse=0.016900 rmse=0.016900 r2=0.231100 
Epoch 14/200 - 验证: loss=0.047800 mae=0.195100 mse=0.047800 rmse=0.047800 r2=-1.251000 
Epoch 15/200 - 训练: loss=0.016700 mae=0.098800 mse=0.016700 rmse=0.016700 r2=0.240200 
Epoch 15/200 - 验证: loss=0.044700 mae=0.187200 mse=0.044700 rmse=0.044700 r2=-1.103700 
【新的最佳模型！】Epoch 15
测试集 digtime: loss=0.042200 mae=0.178700 mse=0.042200 rmse=0.042200 r2=-0.946400 
测试集 timing_ctrl: loss=0.078500 mae=0.256500 mse=0.078500 rmse=0.078500 r2=-1.480900 
测试集 array_128_32_8t: loss=0.041800 mae=0.184700 mse=0.041800 rmse=0.041800 r2=-1.074100 

Epoch 16/200 - 训练: loss=0.016700 mae=0.098700 mse=0.016700 rmse=0.016700 r2=0.240900 
Epoch 16/200 - 验证: loss=0.045100 mae=0.187600 mse=0.045100 rmse=0.045100 r2=-1.122700 
Epoch 17/200 - 训练: loss=0.016200 mae=0.097000 mse=0.016200 rmse=0.016200 r2=0.262500 
Epoch 17/200 - 验证: loss=0.043700 mae=0.183900 mse=0.043700 rmse=0.043700 r2=-1.054900 
【新的最佳模型！】Epoch 17
测试集 digtime: loss=0.042400 mae=0.176400 mse=0.042400 rmse=0.042400 r2=-0.953400 
测试集 timing_ctrl: loss=0.076900 mae=0.254200 mse=0.076900 rmse=0.076900 r2=-1.429300 
测试集 array_128_32_8t: loss=0.040700 mae=0.181000 mse=0.040700 rmse=0.040700 r2=-1.022500 

Epoch 18/200 - 训练: loss=0.016300 mae=0.097600 mse=0.016300 rmse=0.016300 r2=0.256700 
Epoch 18/200 - 验证: loss=0.042400 mae=0.181900 mse=0.042400 rmse=0.042400 r2=-0.996400 
【新的最佳模型！】Epoch 18
测试集 digtime: loss=0.041200 mae=0.176200 mse=0.041200 rmse=0.041200 r2=-0.899500 
测试集 timing_ctrl: loss=0.076100 mae=0.252000 mse=0.076100 rmse=0.076100 r2=-1.402800 
测试集 array_128_32_8t: loss=0.039500 mae=0.179500 mse=0.039500 rmse=0.039500 r2=-0.962700 

Epoch 19/200 - 训练: loss=0.016300 mae=0.096700 mse=0.016300 rmse=0.016300 r2=0.258800 
Epoch 19/200 - 验证: loss=0.044300 mae=0.185600 mse=0.044300 rmse=0.044300 r2=-1.082900 
Epoch 20/200 - 训练: loss=0.015800 mae=0.095600 mse=0.015800 rmse=0.015800 r2=0.279100 
Epoch 20/200 - 验证: loss=0.041500 mae=0.179000 mse=0.041500 rmse=0.041500 r2=-0.951000 
【新的最佳模型！】Epoch 20
测试集 digtime: loss=0.040400 mae=0.173000 mse=0.040400 rmse=0.040400 r2=-0.860900 
测试集 timing_ctrl: loss=0.074700 mae=0.249600 mse=0.074700 rmse=0.074700 r2=-1.361200 
测试集 array_128_32_8t: loss=0.038600 mae=0.176600 mse=0.038600 rmse=0.038600 r2=-0.917500 

Epoch 21/200 - 训练: loss=0.015800 mae=0.095100 mse=0.015800 rmse=0.015800 r2=0.280800 
Epoch 21/200 - 验证: loss=0.040900 mae=0.177500 mse=0.040900 rmse=0.040900 r2=-0.925900 
【新的最佳模型！】Epoch 21
测试集 digtime: loss=0.039600 mae=0.172200 mse=0.039600 rmse=0.039600 r2=-0.824700 
测试集 timing_ctrl: loss=0.074400 mae=0.247900 mse=0.074400 rmse=0.074400 r2=-1.351400 
测试集 array_128_32_8t: loss=0.038200 mae=0.175600 mse=0.038200 rmse=0.038200 r2=-0.895400 

Epoch 22/200 - 训练: loss=0.015600 mae=0.094600 mse=0.015600 rmse=0.015600 r2=0.290600 
Epoch 22/200 - 验证: loss=0.039900 mae=0.174700 mse=0.039900 rmse=0.039900 r2=-0.879100 
【新的最佳模型！】Epoch 22
测试集 digtime: loss=0.038800 mae=0.170400 mse=0.038800 rmse=0.038800 r2=-0.789200 
测试集 timing_ctrl: loss=0.073400 mae=0.245200 mse=0.073400 rmse=0.073400 r2=-1.318800 
测试集 array_128_32_8t: loss=0.037300 mae=0.173100 mse=0.037300 rmse=0.037300 r2=-0.850300 

Epoch 23/200 - 训练: loss=0.015600 mae=0.094500 mse=0.015600 rmse=0.015600 r2=0.289700 
Epoch 23/200 - 验证: loss=0.041300 mae=0.176500 mse=0.041300 rmse=0.041300 r2=-0.943400 
Epoch 24/200 - 训练: loss=0.015500 mae=0.094300 mse=0.015500 rmse=0.015500 r2=0.294800 
Epoch 24/200 - 验证: loss=0.039600 mae=0.175500 mse=0.039600 rmse=0.039600 r2=-0.863800 
【新的最佳模型！】Epoch 24
测试集 digtime: loss=0.037900 mae=0.169800 mse=0.037900 rmse=0.037900 r2=-0.747800 
测试集 timing_ctrl: loss=0.072400 mae=0.244400 mse=0.072400 rmse=0.072400 r2=-1.287000 
测试集 array_128_32_8t: loss=0.037000 mae=0.173800 mse=0.037000 rmse=0.037000 r2=-0.835800 

Epoch 25/200 - 训练: loss=0.015500 mae=0.093700 mse=0.015500 rmse=0.015500 r2=0.296600 
Epoch 25/200 - 验证: loss=0.038200 mae=0.170700 mse=0.038200 rmse=0.038200 r2=-0.799600 
【新的最佳模型！】Epoch 25
测试集 digtime: loss=0.037000 mae=0.165500 mse=0.037000 rmse=0.037000 r2=-0.703800 
测试集 timing_ctrl: loss=0.071000 mae=0.240800 mse=0.071000 rmse=0.071000 r2=-1.242500 
测试集 array_128_32_8t: loss=0.035800 mae=0.169600 mse=0.035800 rmse=0.035800 r2=-0.775900 

Epoch 26/200 - 训练: loss=0.015300 mae=0.092900 mse=0.015300 rmse=0.015300 r2=0.304800 
Epoch 26/200 - 验证: loss=0.039900 mae=0.173300 mse=0.039900 rmse=0.039900 r2=-0.877600 
Epoch 27/200 - 训练: loss=0.015200 mae=0.092800 mse=0.015200 rmse=0.015200 r2=0.307700 
Epoch 27/200 - 验证: loss=0.038900 mae=0.172300 mse=0.038900 rmse=0.038900 r2=-0.828800 
Epoch 28/200 - 训练: loss=0.015000 mae=0.092200 mse=0.015000 rmse=0.015000 r2=0.315200 
Epoch 28/200 - 验证: loss=0.038000 mae=0.171300 mse=0.038000 rmse=0.038000 r2=-0.788100 
【新的最佳模型！】Epoch 28
测试集 digtime: loss=0.036200 mae=0.163700 mse=0.036200 rmse=0.036200 r2=-0.670500 
测试集 timing_ctrl: loss=0.069900 mae=0.241000 mse=0.069900 rmse=0.069900 r2=-1.207800 
测试集 array_128_32_8t: loss=0.035600 mae=0.170400 mse=0.035600 rmse=0.035600 r2=-0.766200 

Epoch 29/200 - 训练: loss=0.015100 mae=0.092400 mse=0.015100 rmse=0.015100 r2=0.314100 
Epoch 29/200 - 验证: loss=0.036400 mae=0.166300 mse=0.036400 rmse=0.036400 r2=-0.711400 
【新的最佳模型！】Epoch 29
测试集 digtime: loss=0.034700 mae=0.160500 mse=0.034700 rmse=0.034700 r2=-0.598600 
测试集 timing_ctrl: loss=0.068000 mae=0.235300 mse=0.068000 rmse=0.068000 r2=-1.148400 
测试集 array_128_32_8t: loss=0.033900 mae=0.164800 mse=0.033900 rmse=0.033900 r2=-0.683700 

Epoch 30/200 - 训练: loss=0.014800 mae=0.091600 mse=0.014800 rmse=0.014800 r2=0.325300 
Epoch 30/200 - 验证: loss=0.037800 mae=0.168600 mse=0.037800 rmse=0.037800 r2=-0.781200 
Epoch 31/200 - 训练: loss=0.014900 mae=0.091600 mse=0.014900 rmse=0.014900 r2=0.319700 
Epoch 31/200 - 验证: loss=0.034700 mae=0.162900 mse=0.034700 rmse=0.034700 r2=-0.634800 
【新的最佳模型！】Epoch 31
测试集 digtime: loss=0.033100 mae=0.157000 mse=0.033100 rmse=0.033100 r2=-0.526300 
测试集 timing_ctrl: loss=0.065600 mae=0.231200 mse=0.065600 rmse=0.065600 r2=-1.073600 
测试集 array_128_32_8t: loss=0.032400 mae=0.161700 mse=0.032400 rmse=0.032400 r2=-0.611700 

Epoch 32/200 - 训练: loss=0.014900 mae=0.091400 mse=0.014900 rmse=0.014900 r2=0.320100 
Epoch 32/200 - 验证: loss=0.036000 mae=0.164500 mse=0.036000 rmse=0.036000 r2=-0.692000 
Epoch 33/200 - 训练: loss=0.014800 mae=0.091400 mse=0.014800 rmse=0.014800 r2=0.324600 
Epoch 33/200 - 验证: loss=0.035000 mae=0.163300 mse=0.035000 rmse=0.035000 r2=-0.648500 
Epoch 34/200 - 训练: loss=0.014800 mae=0.091100 mse=0.014800 rmse=0.014800 r2=0.326900 
Epoch 34/200 - 验证: loss=0.033300 mae=0.158000 mse=0.033300 rmse=0.033300 r2=-0.566000 
【新的最佳模型！】Epoch 34
测试集 digtime: loss=0.032100 mae=0.152900 mse=0.032100 rmse=0.032100 r2=-0.480900 
测试集 timing_ctrl: loss=0.063700 mae=0.226500 mse=0.063700 rmse=0.063700 r2=-1.013800 
测试集 array_128_32_8t: loss=0.031100 mae=0.156800 mse=0.031100 rmse=0.031100 r2=-0.543500 

Epoch 35/200 - 训练: loss=0.014800 mae=0.091000 mse=0.014800 rmse=0.014800 r2=0.326400 
Epoch 35/200 - 验证: loss=0.034100 mae=0.160100 mse=0.034100 rmse=0.034100 r2=-0.604000 
Epoch 36/200 - 训练: loss=0.014500 mae=0.089900 mse=0.014500 rmse=0.014500 r2=0.339700 
Epoch 36/200 - 验证: loss=0.032100 mae=0.155500 mse=0.032100 rmse=0.032100 r2=-0.508500 
【新的最佳模型！】Epoch 36
测试集 digtime: loss=0.030900 mae=0.150200 mse=0.030900 rmse=0.030900 r2=-0.425000 
测试集 timing_ctrl: loss=0.061900 mae=0.223700 mse=0.061900 rmse=0.061900 r2=-0.955100 
测试集 array_128_32_8t: loss=0.030000 mae=0.154600 mse=0.030000 rmse=0.030000 r2=-0.488800 

Epoch 37/200 - 训练: loss=0.014600 mae=0.090100 mse=0.014600 rmse=0.014600 r2=0.334700 
Epoch 37/200 - 验证: loss=0.031200 mae=0.153800 mse=0.031200 rmse=0.031200 r2=-0.468400 
【新的最佳模型！】Epoch 37
测试集 digtime: loss=0.029800 mae=0.148200 mse=0.029800 rmse=0.029800 r2=-0.374800 
测试集 timing_ctrl: loss=0.060300 mae=0.221200 mse=0.060300 rmse=0.060300 r2=-0.904700 
测试集 array_128_32_8t: loss=0.029200 mae=0.152800 mse=0.029200 rmse=0.029200 r2=-0.449400 

Epoch 38/200 - 训练: loss=0.014500 mae=0.090000 mse=0.014500 rmse=0.014500 r2=0.339600 
Epoch 38/200 - 验证: loss=0.032900 mae=0.157300 mse=0.032900 rmse=0.032900 r2=-0.548300 
Epoch 39/200 - 训练: loss=0.014600 mae=0.090100 mse=0.014600 rmse=0.014600 r2=0.335900 
Epoch 39/200 - 验证: loss=0.030100 mae=0.150900 mse=0.030100 rmse=0.030100 r2=-0.417700 
【新的最佳模型！】Epoch 39
测试集 digtime: loss=0.029400 mae=0.146200 mse=0.029400 rmse=0.029400 r2=-0.357200 
测试集 timing_ctrl: loss=0.058800 mae=0.219300 mse=0.058800 rmse=0.058800 r2=-0.858600 
测试集 array_128_32_8t: loss=0.028100 mae=0.149900 mse=0.028100 rmse=0.028100 r2=-0.396400 

Epoch 40/200 - 训练: loss=0.014500 mae=0.090000 mse=0.014500 rmse=0.014500 r2=0.340300 
Epoch 40/200 - 验证: loss=0.032300 mae=0.155900 mse=0.032300 rmse=0.032300 r2=-0.520800 
Epoch 41/200 - 训练: loss=0.014600 mae=0.090600 mse=0.014600 rmse=0.014600 r2=0.333200 
Epoch 41/200 - 验证: loss=0.027900 mae=0.144500 mse=0.027900 rmse=0.027900 r2=-0.311100 
【新的最佳模型！】Epoch 41
测试集 digtime: loss=0.027200 mae=0.140500 mse=0.027200 rmse=0.027200 r2=-0.253300 
测试集 timing_ctrl: loss=0.055300 mae=0.211000 mse=0.055300 rmse=0.055300 r2=-0.747400 
测试集 array_128_32_8t: loss=0.026000 mae=0.142700 mse=0.026000 rmse=0.026000 r2=-0.289000 

Epoch 42/200 - 训练: loss=0.014400 mae=0.089300 mse=0.014400 rmse=0.014400 r2=0.344400 
Epoch 42/200 - 验证: loss=0.031900 mae=0.155300 mse=0.031900 rmse=0.031900 r2=-0.500100 
Epoch 43/200 - 训练: loss=0.014400 mae=0.089600 mse=0.014400 rmse=0.014400 r2=0.342800 
Epoch 43/200 - 验证: loss=0.029300 mae=0.148300 mse=0.029300 rmse=0.029300 r2=-0.379700 
Epoch 44/200 - 训练: loss=0.014300 mae=0.088900 mse=0.014300 rmse=0.014300 r2=0.347400 
Epoch 44/200 - 验证: loss=0.029300 mae=0.147900 mse=0.029300 rmse=0.029300 r2=-0.378900 
Epoch 45/200 - 训练: loss=0.014500 mae=0.089600 mse=0.014500 rmse=0.014500 r2=0.341700 
Epoch 45/200 - 验证: loss=0.030400 mae=0.151900 mse=0.030400 rmse=0.030400 r2=-0.429100 
Epoch 46/200 - 训练: loss=0.014400 mae=0.089000 mse=0.014400 rmse=0.014400 r2=0.344800 
Epoch 46/200 - 验证: loss=0.028600 mae=0.148100 mse=0.028600 rmse=0.028600 r2=-0.348000 
Epoch 47/200 - 训练: loss=0.014300 mae=0.088700 mse=0.014300 rmse=0.014300 r2=0.348000 
Epoch 47/200 - 验证: loss=0.027700 mae=0.144900 mse=0.027700 rmse=0.027700 r2=-0.306100 
【新的最佳模型！】Epoch 47
测试集 digtime: loss=0.027100 mae=0.140200 mse=0.027100 rmse=0.027100 r2=-0.247600 
测试集 timing_ctrl: loss=0.054900 mae=0.212300 mse=0.054900 rmse=0.054900 r2=-0.734400 
测试集 array_128_32_8t: loss=0.025700 mae=0.142900 mse=0.025700 rmse=0.025700 r2=-0.275500 

Epoch 48/200 - 训练: loss=0.014300 mae=0.088800 mse=0.014300 rmse=0.014300 r2=0.348600 
Epoch 48/200 - 验证: loss=0.027800 mae=0.144700 mse=0.027800 rmse=0.027800 r2=-0.309500 
Epoch 49/200 - 训练: loss=0.014300 mae=0.089000 mse=0.014300 rmse=0.014300 r2=0.350200 
Epoch 49/200 - 验证: loss=0.028600 mae=0.148200 mse=0.028600 rmse=0.028600 r2=-0.345100 
Epoch 50/200 - 训练: loss=0.014300 mae=0.088800 mse=0.014300 rmse=0.014300 r2=0.347400 
Epoch 50/200 - 验证: loss=0.027700 mae=0.145700 mse=0.027700 rmse=0.027700 r2=-0.301900 
【新的最佳模型！】Epoch 50
测试集 digtime: loss=0.026600 mae=0.139900 mse=0.026600 rmse=0.026600 r2=-0.224300 
测试集 timing_ctrl: loss=0.054300 mae=0.212300 mse=0.054300 rmse=0.054300 r2=-0.716500 
测试集 array_128_32_8t: loss=0.025600 mae=0.143300 mse=0.025600 rmse=0.025600 r2=-0.271100 

Epoch 51/200 - 训练: loss=0.014200 mae=0.088300 mse=0.014200 rmse=0.014200 r2=0.354700 
Epoch 51/200 - 验证: loss=0.025400 mae=0.138100 mse=0.025400 rmse=0.025400 r2=-0.197200 
【新的最佳模型！】Epoch 51
测试集 digtime: loss=0.025300 mae=0.134800 mse=0.025300 rmse=0.025300 r2=-0.165400 
测试集 timing_ctrl: loss=0.051300 mae=0.205100 mse=0.051300 rmse=0.051300 r2=-0.620700 
测试集 array_128_32_8t: loss=0.023500 mae=0.135800 mse=0.023500 rmse=0.023500 r2=-0.168300 

Epoch 52/200 - 训练: loss=0.014300 mae=0.088800 mse=0.014300 rmse=0.014300 r2=0.348300 
Epoch 52/200 - 验证: loss=0.027200 mae=0.144500 mse=0.027200 rmse=0.027200 r2=-0.281400 
Epoch 53/200 - 训练: loss=0.014100 mae=0.088200 mse=0.014100 rmse=0.014100 r2=0.356200 
Epoch 53/200 - 验证: loss=0.027200 mae=0.142400 mse=0.027200 rmse=0.027200 r2=-0.280400 
Epoch 54/200 - 训练: loss=0.014200 mae=0.088400 mse=0.014200 rmse=0.014200 r2=0.354000 
Epoch 54/200 - 验证: loss=0.026200 mae=0.141000 mse=0.026200 rmse=0.026200 r2=-0.234800 
Epoch 55/200 - 训练: loss=0.014200 mae=0.088600 mse=0.014200 rmse=0.014200 r2=0.352600 
Epoch 55/200 - 验证: loss=0.027500 mae=0.143900 mse=0.027500 rmse=0.027500 r2=-0.293800 
Epoch 56/200 - 训练: loss=0.014200 mae=0.088500 mse=0.014200 rmse=0.014200 r2=0.351300 
Epoch 56/200 - 验证: loss=0.026100 mae=0.140200 mse=0.026100 rmse=0.026100 r2=-0.228100 
Epoch 57/200 - 训练: loss=0.014200 mae=0.088500 mse=0.014200 rmse=0.014200 r2=0.354100 
Epoch 57/200 - 验证: loss=0.027300 mae=0.144300 mse=0.027300 rmse=0.027300 r2=-0.285800 
Epoch 58/200 - 训练: loss=0.014100 mae=0.087800 mse=0.014100 rmse=0.014100 r2=0.360200 
Epoch 58/200 - 验证: loss=0.027300 mae=0.143400 mse=0.027300 rmse=0.027300 r2=-0.287200 
Epoch 59/200 - 训练: loss=0.014100 mae=0.088000 mse=0.014100 rmse=0.014100 r2=0.360200 
Epoch 59/200 - 验证: loss=0.024300 mae=0.135000 mse=0.024300 rmse=0.024300 r2=-0.142800 
【新的最佳模型！】Epoch 59
测试集 digtime: loss=0.024200 mae=0.132100 mse=0.024200 rmse=0.024200 r2=-0.114400 
测试集 timing_ctrl: loss=0.049100 mae=0.201200 mse=0.049100 rmse=0.049100 r2=-0.550200 
测试集 array_128_32_8t: loss=0.022300 mae=0.131700 mse=0.022300 rmse=0.022300 r2=-0.106000 

Epoch 60/200 - 训练: loss=0.014100 mae=0.088000 mse=0.014100 rmse=0.014100 r2=0.356500 
Epoch 60/200 - 验证: loss=0.025700 mae=0.139100 mse=0.025700 rmse=0.025700 r2=-0.208200 
Epoch 61/200 - 训练: loss=0.014100 mae=0.088100 mse=0.014100 rmse=0.014100 r2=0.357700 
Epoch 61/200 - 验证: loss=0.025500 mae=0.138500 mse=0.025500 rmse=0.025500 r2=-0.199200 
Epoch 62/200 - 训练: loss=0.014000 mae=0.087800 mse=0.014000 rmse=0.014000 r2=0.361700 
Epoch 62/200 - 验证: loss=0.025200 mae=0.137800 mse=0.025200 rmse=0.025200 r2=-0.187500 
Epoch 63/200 - 训练: loss=0.014000 mae=0.087800 mse=0.014000 rmse=0.014000 r2=0.360600 
Epoch 63/200 - 验证: loss=0.024400 mae=0.134400 mse=0.024400 rmse=0.024400 r2=-0.147200 
Epoch 64/200 - 训练: loss=0.014000 mae=0.088100 mse=0.014000 rmse=0.014000 r2=0.361100 
Epoch 64/200 - 验证: loss=0.023500 mae=0.132300 mse=0.023500 rmse=0.023500 r2=-0.104800 
【新的最佳模型！】Epoch 64
测试集 digtime: loss=0.024100 mae=0.130500 mse=0.024100 rmse=0.024100 r2=-0.110600 
测试集 timing_ctrl: loss=0.048100 mae=0.199000 mse=0.048100 rmse=0.048100 r2=-0.519200 
测试集 array_128_32_8t: loss=0.021500 mae=0.129300 mse=0.021500 rmse=0.021500 r2=-0.066500 

Epoch 65/200 - 训练: loss=0.013900 mae=0.087100 mse=0.013900 rmse=0.013900 r2=0.366500 
Epoch 65/200 - 验证: loss=0.023800 mae=0.133500 mse=0.023800 rmse=0.023800 r2=-0.121500 
Epoch 66/200 - 训练: loss=0.014000 mae=0.087500 mse=0.014000 rmse=0.014000 r2=0.361300 
Epoch 66/200 - 验证: loss=0.024800 mae=0.136400 mse=0.024800 rmse=0.024800 r2=-0.167900 
Epoch 67/200 - 训练: loss=0.013900 mae=0.087200 mse=0.013900 rmse=0.013900 r2=0.368100 
Epoch 67/200 - 验证: loss=0.022700 mae=0.130200 mse=0.022700 rmse=0.022700 r2=-0.069000 
【新的最佳模型！】Epoch 67
测试集 digtime: loss=0.023600 mae=0.129200 mse=0.023600 rmse=0.023600 r2=-0.086700 
测试集 timing_ctrl: loss=0.046900 mae=0.196300 mse=0.046900 rmse=0.046900 r2=-0.480200 
测试集 array_128_32_8t: loss=0.020900 mae=0.127300 mse=0.020900 rmse=0.020900 r2=-0.037900 

Epoch 68/200 - 训练: loss=0.013900 mae=0.087500 mse=0.013900 rmse=0.013900 r2=0.365500 
Epoch 68/200 - 验证: loss=0.024700 mae=0.136800 mse=0.024700 rmse=0.024700 r2=-0.161200 
Epoch 69/200 - 训练: loss=0.013800 mae=0.087100 mse=0.013800 rmse=0.013800 r2=0.369800 
Epoch 69/200 - 验证: loss=0.022700 mae=0.130100 mse=0.022700 rmse=0.022700 r2=-0.068800 
【新的最佳模型！】Epoch 69
测试集 digtime: loss=0.023800 mae=0.130000 mse=0.023800 rmse=0.023800 r2=-0.098700 
测试集 timing_ctrl: loss=0.046900 mae=0.196400 mse=0.046900 rmse=0.046900 r2=-0.483100 
测试集 array_128_32_8t: loss=0.020800 mae=0.127200 mse=0.020800 rmse=0.020800 r2=-0.034700 

Epoch 70/200 - 训练: loss=0.013900 mae=0.087000 mse=0.013900 rmse=0.013900 r2=0.369300 
Epoch 70/200 - 验证: loss=0.023800 mae=0.133800 mse=0.023800 rmse=0.023800 r2=-0.118300 
Epoch 71/200 - 训练: loss=0.013800 mae=0.086700 mse=0.013800 rmse=0.013800 r2=0.373100 
Epoch 71/200 - 验证: loss=0.024100 mae=0.135200 mse=0.024100 rmse=0.024100 r2=-0.135600 
Epoch 72/200 - 训练: loss=0.013900 mae=0.087200 mse=0.013900 rmse=0.013900 r2=0.368300 
Epoch 72/200 - 验证: loss=0.023200 mae=0.131400 mse=0.023200 rmse=0.023200 r2=-0.094000 
Epoch 73/200 - 训练: loss=0.013800 mae=0.087000 mse=0.013800 rmse=0.013800 r2=0.369600 
Epoch 73/200 - 验证: loss=0.022200 mae=0.127400 mse=0.022200 rmse=0.022200 r2=-0.043800 
【新的最佳模型！】Epoch 73
测试集 digtime: loss=0.024000 mae=0.129700 mse=0.024000 rmse=0.024000 r2=-0.105800 
测试集 timing_ctrl: loss=0.046800 mae=0.192600 mse=0.046800 rmse=0.046800 r2=-0.477400 
测试集 array_128_32_8t: loss=0.020300 mae=0.124200 mse=0.020300 rmse=0.020300 r2=-0.007100 

Epoch 74/200 - 训练: loss=0.013800 mae=0.086900 mse=0.013800 rmse=0.013800 r2=0.370700 
Epoch 74/200 - 验证: loss=0.022400 mae=0.130000 mse=0.022400 rmse=0.022400 r2=-0.055000 
Epoch 75/200 - 训练: loss=0.013800 mae=0.087000 mse=0.013800 rmse=0.013800 r2=0.370200 
Epoch 75/200 - 验证: loss=0.022500 mae=0.129700 mse=0.022500 rmse=0.022500 r2=-0.058100 
Epoch 76/200 - 训练: loss=0.013700 mae=0.086600 mse=0.013700 rmse=0.013700 r2=0.377100 
Epoch 76/200 - 验证: loss=0.023200 mae=0.131700 mse=0.023200 rmse=0.023200 r2=-0.093900 
Epoch 77/200 - 训练: loss=0.013700 mae=0.086600 mse=0.013700 rmse=0.013700 r2=0.375600 
Epoch 77/200 - 验证: loss=0.021900 mae=0.127200 mse=0.021900 rmse=0.021900 r2=-0.031700 
【新的最佳模型！】Epoch 77
测试集 digtime: loss=0.024200 mae=0.131300 mse=0.024200 rmse=0.024200 r2=-0.117300 
测试集 timing_ctrl: loss=0.046500 mae=0.191800 mse=0.046500 rmse=0.046500 r2=-0.468400 
测试集 array_128_32_8t: loss=0.019500 mae=0.122000 mse=0.019500 rmse=0.019500 r2=0.031800 

Epoch 78/200 - 训练: loss=0.013600 mae=0.086000 mse=0.013600 rmse=0.013600 r2=0.382700 
Epoch 78/200 - 验证: loss=0.021500 mae=0.126200 mse=0.021500 rmse=0.021500 r2=-0.012100 
【新的最佳模型！】Epoch 78
测试集 digtime: loss=0.023600 mae=0.129600 mse=0.023600 rmse=0.023600 r2=-0.085900 
测试集 timing_ctrl: loss=0.045600 mae=0.191000 mse=0.045600 rmse=0.045600 r2=-0.441100 
测试集 array_128_32_8t: loss=0.019000 mae=0.120600 mse=0.019000 rmse=0.019000 r2=0.056500 

Epoch 79/200 - 训练: loss=0.013700 mae=0.086700 mse=0.013700 rmse=0.013700 r2=0.376800 
Epoch 79/200 - 验证: loss=0.022500 mae=0.129900 mse=0.022500 rmse=0.022500 r2=-0.059500 
Epoch 80/200 - 训练: loss=0.013600 mae=0.086100 mse=0.013600 rmse=0.013600 r2=0.380500 
Epoch 80/200 - 验证: loss=0.021900 mae=0.127500 mse=0.021900 rmse=0.021900 r2=-0.031000 
Epoch 81/200 - 训练: loss=0.013600 mae=0.086100 mse=0.013600 rmse=0.013600 r2=0.381500 
Epoch 81/200 - 验证: loss=0.021500 mae=0.126600 mse=0.021500 rmse=0.021500 r2=-0.013700 
Epoch 82/200 - 训练: loss=0.013500 mae=0.085600 mse=0.013500 rmse=0.013500 r2=0.383300 
Epoch 82/200 - 验证: loss=0.021800 mae=0.127500 mse=0.021800 rmse=0.021800 r2=-0.025100 
Epoch 83/200 - 训练: loss=0.013500 mae=0.085700 mse=0.013500 rmse=0.013500 r2=0.384900 
Epoch 83/200 - 验证: loss=0.020500 mae=0.122900 mse=0.020500 rmse=0.020500 r2=0.036100 
【新的最佳模型！】Epoch 83
测试集 digtime: loss=0.023100 mae=0.127700 mse=0.023100 rmse=0.023100 r2=-0.065500 
测试集 timing_ctrl: loss=0.044200 mae=0.187000 mse=0.044200 rmse=0.044200 r2=-0.396400 
测试集 array_128_32_8t: loss=0.017500 mae=0.114300 mse=0.017500 rmse=0.017500 r2=0.129900 

Epoch 84/200 - 训练: loss=0.013500 mae=0.085500 mse=0.013500 rmse=0.013500 r2=0.385700 
Epoch 84/200 - 验证: loss=0.021400 mae=0.126300 mse=0.021400 rmse=0.021400 r2=-0.009500 
Epoch 85/200 - 训练: loss=0.013500 mae=0.085700 mse=0.013500 rmse=0.013500 r2=0.384700 
Epoch 85/200 - 验证: loss=0.021300 mae=0.126100 mse=0.021300 rmse=0.021300 r2=-0.002800 
Epoch 86/200 - 训练: loss=0.013500 mae=0.085400 mse=0.013500 rmse=0.013500 r2=0.387300 
Epoch 86/200 - 验证: loss=0.020100 mae=0.121800 mse=0.020100 rmse=0.020100 r2=0.055100 
【新的最佳模型！】Epoch 86
测试集 digtime: loss=0.022600 mae=0.126100 mse=0.022600 rmse=0.022600 r2=-0.043300 
测试集 timing_ctrl: loss=0.043500 mae=0.186000 mse=0.043500 rmse=0.043500 r2=-0.375500 
测试集 array_128_32_8t: loss=0.017000 mae=0.111600 mse=0.017000 rmse=0.017000 r2=0.157400 

Epoch 87/200 - 训练: loss=0.013500 mae=0.085700 mse=0.013500 rmse=0.013500 r2=0.386500 
Epoch 87/200 - 验证: loss=0.020200 mae=0.122100 mse=0.020200 rmse=0.020200 r2=0.047200 
Epoch 88/200 - 训练: loss=0.013500 mae=0.085600 mse=0.013500 rmse=0.013500 r2=0.387400 
Epoch 88/200 - 验证: loss=0.023500 mae=0.133300 mse=0.023500 rmse=0.023500 r2=-0.105700 
Epoch 89/200 - 训练: loss=0.013400 mae=0.085600 mse=0.013400 rmse=0.013400 r2=0.389500 
Epoch 89/200 - 验证: loss=0.020600 mae=0.123500 mse=0.020600 rmse=0.020600 r2=0.031800 
Epoch 90/200 - 训练: loss=0.013300 mae=0.085200 mse=0.013300 rmse=0.013300 r2=0.392700 
Epoch 90/200 - 验证: loss=0.021100 mae=0.124700 mse=0.021100 rmse=0.021100 r2=0.007700 
Epoch 91/200 - 训练: loss=0.013400 mae=0.085300 mse=0.013400 rmse=0.013400 r2=0.390200 
Epoch 91/200 - 验证: loss=0.020400 mae=0.123000 mse=0.020400 rmse=0.020400 r2=0.037500 
Epoch 92/200 - 训练: loss=0.013400 mae=0.085200 mse=0.013400 rmse=0.013400 r2=0.390700 
Epoch 92/200 - 验证: loss=0.019300 mae=0.118900 mse=0.019300 rmse=0.019300 r2=0.093600 
【新的最佳模型！】Epoch 92
测试集 digtime: loss=0.022500 mae=0.125600 mse=0.022500 rmse=0.022500 r2=-0.036300 
测试集 timing_ctrl: loss=0.042900 mae=0.184300 mse=0.042900 rmse=0.042900 r2=-0.354200 
测试集 array_128_32_8t: loss=0.016100 mae=0.107400 mse=0.016100 rmse=0.016100 r2=0.198600 

Epoch 93/200 - 训练: loss=0.013400 mae=0.085100 mse=0.013400 rmse=0.013400 r2=0.391800 
Epoch 93/200 - 验证: loss=0.020400 mae=0.122700 mse=0.020400 rmse=0.020400 r2=0.038300 
Epoch 94/200 - 训练: loss=0.013300 mae=0.084600 mse=0.013300 rmse=0.013300 r2=0.395900 
Epoch 94/200 - 验证: loss=0.020100 mae=0.121500 mse=0.020100 rmse=0.020100 r2=0.053800 
Epoch 95/200 - 训练: loss=0.013300 mae=0.084900 mse=0.013300 rmse=0.013300 r2=0.394200 
Epoch 95/200 - 验证: loss=0.019000 mae=0.117400 mse=0.019000 rmse=0.019000 r2=0.105100 
【新的最佳模型！】Epoch 95
测试集 digtime: loss=0.022400 mae=0.124200 mse=0.022400 rmse=0.022400 r2=-0.030800 
测试集 timing_ctrl: loss=0.042400 mae=0.181800 mse=0.042400 rmse=0.042400 r2=-0.340200 
测试集 array_128_32_8t: loss=0.015900 mae=0.106200 mse=0.015900 rmse=0.015900 r2=0.209500 

Epoch 96/200 - 训练: loss=0.013300 mae=0.084900 mse=0.013300 rmse=0.013300 r2=0.394000 
Epoch 96/200 - 验证: loss=0.018800 mae=0.116900 mse=0.018800 rmse=0.018800 r2=0.114500 
【新的最佳模型！】Epoch 96
测试集 digtime: loss=0.022300 mae=0.124300 mse=0.022300 rmse=0.022300 r2=-0.028200 
测试集 timing_ctrl: loss=0.042300 mae=0.182800 mse=0.042300 rmse=0.042300 r2=-0.337000 
测试集 array_128_32_8t: loss=0.015800 mae=0.105700 mse=0.015800 rmse=0.015800 r2=0.215800 

Epoch 97/200 - 训练: loss=0.013300 mae=0.084900 mse=0.013300 rmse=0.013300 r2=0.395000 
Epoch 97/200 - 验证: loss=0.018800 mae=0.117000 mse=0.018800 rmse=0.018800 r2=0.113100 
Epoch 98/200 - 训练: loss=0.013300 mae=0.085000 mse=0.013300 rmse=0.013300 r2=0.394600 
Epoch 98/200 - 验证: loss=0.019500 mae=0.119700 mse=0.019500 rmse=0.019500 r2=0.082400 
Epoch 99/200 - 训练: loss=0.013300 mae=0.085000 mse=0.013300 rmse=0.013300 r2=0.396700 
Epoch 99/200 - 验证: loss=0.019000 mae=0.118200 mse=0.019000 rmse=0.019000 r2=0.105700 
Epoch 100/200 - 训练: loss=0.013300 mae=0.084800 mse=0.013300 rmse=0.013300 r2=0.393600 
Epoch 100/200 - 验证: loss=0.020700 mae=0.123300 mse=0.020700 rmse=0.020700 r2=0.026500 
Epoch 101/200 - 训练: loss=0.013200 mae=0.084400 mse=0.013200 rmse=0.013200 r2=0.397600 
Epoch 101/200 - 验证: loss=0.018200 mae=0.114100 mse=0.018200 rmse=0.018200 r2=0.142300 
【新的最佳模型！】Epoch 101
测试集 digtime: loss=0.021700 mae=0.122000 mse=0.021700 rmse=0.021700 r2=0.000300 
测试集 timing_ctrl: loss=0.041000 mae=0.178000 mse=0.041000 rmse=0.041000 r2=-0.294600 
测试集 array_128_32_8t: loss=0.015200 mae=0.102000 mse=0.015200 rmse=0.015200 r2=0.246600 

Epoch 102/200 - 训练: loss=0.013200 mae=0.084400 mse=0.013200 rmse=0.013200 r2=0.397600 
Epoch 102/200 - 验证: loss=0.019600 mae=0.120200 mse=0.019600 rmse=0.019600 r2=0.075700 
Epoch 103/200 - 训练: loss=0.013300 mae=0.084500 mse=0.013300 rmse=0.013300 r2=0.396700 
Epoch 103/200 - 验证: loss=0.019000 mae=0.117300 mse=0.019000 rmse=0.019000 r2=0.105900 
Epoch 104/200 - 训练: loss=0.013300 mae=0.084600 mse=0.013300 rmse=0.013300 r2=0.394800 
Epoch 104/200 - 验证: loss=0.019100 mae=0.118100 mse=0.019100 rmse=0.019100 r2=0.100500 
Epoch 105/200 - 训练: loss=0.013200 mae=0.084200 mse=0.013200 rmse=0.013200 r2=0.400100 
Epoch 105/200 - 验证: loss=0.018600 mae=0.115800 mse=0.018600 rmse=0.018600 r2=0.125100 
Epoch 106/200 - 训练: loss=0.013300 mae=0.084500 mse=0.013300 rmse=0.013300 r2=0.394900 
Epoch 106/200 - 验证: loss=0.017400 mae=0.112200 mse=0.017400 rmse=0.017400 r2=0.178800 
【新的最佳模型！】Epoch 106
测试集 digtime: loss=0.020400 mae=0.118900 mse=0.020400 rmse=0.020400 r2=0.058100 
测试集 timing_ctrl: loss=0.038900 mae=0.175300 mse=0.038900 rmse=0.038900 r2=-0.227700 
测试集 array_128_32_8t: loss=0.014700 mae=0.100200 mse=0.014700 rmse=0.014700 r2=0.268500 

Epoch 107/200 - 训练: loss=0.013300 mae=0.084600 mse=0.013300 rmse=0.013300 r2=0.395900 
Epoch 107/200 - 验证: loss=0.018200 mae=0.115300 mse=0.018200 rmse=0.018200 r2=0.141400 
Epoch 108/200 - 训练: loss=0.013200 mae=0.084100 mse=0.013200 rmse=0.013200 r2=0.399100 
Epoch 108/200 - 验证: loss=0.018900 mae=0.116900 mse=0.018900 rmse=0.018900 r2=0.112400 
Epoch 109/200 - 训练: loss=0.013200 mae=0.084300 mse=0.013200 rmse=0.013200 r2=0.399900 
Epoch 109/200 - 验证: loss=0.018000 mae=0.114100 mse=0.018000 rmse=0.018000 r2=0.151900 
Epoch 110/200 - 训练: loss=0.013200 mae=0.084400 mse=0.013200 rmse=0.013200 r2=0.398600 
Epoch 110/200 - 验证: loss=0.019300 mae=0.119700 mse=0.019300 rmse=0.019300 r2=0.089400 
Epoch 111/200 - 训练: loss=0.013200 mae=0.084100 mse=0.013200 rmse=0.013200 r2=0.400800 
Epoch 111/200 - 验证: loss=0.018700 mae=0.117200 mse=0.018700 rmse=0.018700 r2=0.122200 
Epoch 112/200 - 训练: loss=0.013200 mae=0.084300 mse=0.013200 rmse=0.013200 r2=0.396900 
Epoch 112/200 - 验证: loss=0.017600 mae=0.112700 mse=0.017600 rmse=0.017600 r2=0.172400 
Epoch 113/200 - 训练: loss=0.013200 mae=0.084100 mse=0.013200 rmse=0.013200 r2=0.400900 
Epoch 113/200 - 验证: loss=0.018600 mae=0.117200 mse=0.018600 rmse=0.018600 r2=0.123800 
Epoch 114/200 - 训练: loss=0.013200 mae=0.084400 mse=0.013200 rmse=0.013200 r2=0.397100 
Epoch 114/200 - 验证: loss=0.018800 mae=0.116900 mse=0.018800 rmse=0.018800 r2=0.114400 
Epoch 115/200 - 训练: loss=0.013100 mae=0.083900 mse=0.013100 rmse=0.013100 r2=0.403300 
Epoch 115/200 - 验证: loss=0.019000 mae=0.118600 mse=0.019000 rmse=0.019000 r2=0.103400 
Epoch 116/200 - 训练: loss=0.013200 mae=0.084200 mse=0.013200 rmse=0.013200 r2=0.399800 
Epoch 116/200 - 验证: loss=0.018700 mae=0.116800 mse=0.018700 rmse=0.018700 r2=0.119300 
Epoch 117/200 - 训练: loss=0.013100 mae=0.084000 mse=0.013100 rmse=0.013100 r2=0.403300 
Epoch 117/200 - 验证: loss=0.018300 mae=0.115400 mse=0.018300 rmse=0.018300 r2=0.139800 
Epoch 118/200 - 训练: loss=0.013200 mae=0.084400 mse=0.013200 rmse=0.013200 r2=0.399400 
Epoch 118/200 - 验证: loss=0.017400 mae=0.112000 mse=0.017400 rmse=0.017400 r2=0.178900 
【新的最佳模型！】Epoch 118
测试集 digtime: loss=0.020300 mae=0.118400 mse=0.020300 rmse=0.020300 r2=0.062300 
测试集 timing_ctrl: loss=0.038600 mae=0.174400 mse=0.038600 rmse=0.038600 r2=-0.219100 
测试集 array_128_32_8t: loss=0.014700 mae=0.100800 mse=0.014700 rmse=0.014700 r2=0.268700 

Epoch 119/200 - 训练: loss=0.013100 mae=0.084000 mse=0.013100 rmse=0.013100 r2=0.402400 
Epoch 119/200 - 验证: loss=0.017700 mae=0.112900 mse=0.017700 rmse=0.017700 r2=0.168600 
Epoch 120/200 - 训练: loss=0.013200 mae=0.084100 mse=0.013200 rmse=0.013200 r2=0.400900 
Epoch 120/200 - 验证: loss=0.017400 mae=0.111500 mse=0.017400 rmse=0.017400 r2=0.179300 
【新的最佳模型！】Epoch 120
测试集 digtime: loss=0.020600 mae=0.118500 mse=0.020600 rmse=0.020600 r2=0.049300 
测试集 timing_ctrl: loss=0.039100 mae=0.173900 mse=0.039100 rmse=0.039100 r2=-0.234600 
测试集 array_128_32_8t: loss=0.014900 mae=0.101400 mse=0.014900 rmse=0.014900 r2=0.262100 

Epoch 121/200 - 训练: loss=0.013100 mae=0.083900 mse=0.013100 rmse=0.013100 r2=0.404600 
Epoch 121/200 - 验证: loss=0.018400 mae=0.115500 mse=0.018400 rmse=0.018400 r2=0.135200 
Epoch 122/200 - 训练: loss=0.013100 mae=0.083900 mse=0.013100 rmse=0.013100 r2=0.403900 
Epoch 122/200 - 验证: loss=0.018100 mae=0.114600 mse=0.018100 rmse=0.018100 r2=0.147900 
Epoch 123/200 - 训练: loss=0.013100 mae=0.084100 mse=0.013100 rmse=0.013100 r2=0.403300 
Epoch 123/200 - 验证: loss=0.017500 mae=0.112000 mse=0.017500 rmse=0.017500 r2=0.174900 
Epoch 124/200 - 训练: loss=0.013100 mae=0.083600 mse=0.013100 rmse=0.013100 r2=0.405800 
Epoch 124/200 - 验证: loss=0.017200 mae=0.111200 mse=0.017200 rmse=0.017200 r2=0.190700 
【新的最佳模型！】Epoch 124
测试集 digtime: loss=0.019900 mae=0.117400 mse=0.019900 rmse=0.019900 r2=0.082800 
测试集 timing_ctrl: loss=0.037600 mae=0.172400 mse=0.037600 rmse=0.037600 r2=-0.189200 
测试集 array_128_32_8t: loss=0.014500 mae=0.099500 mse=0.014500 rmse=0.014500 r2=0.278800 

Epoch 125/200 - 训练: loss=0.013100 mae=0.083900 mse=0.013100 rmse=0.013100 r2=0.403900 
Epoch 125/200 - 验证: loss=0.017200 mae=0.110900 mse=0.017200 rmse=0.017200 r2=0.192600 
【新的最佳模型！】Epoch 125
测试集 digtime: loss=0.020400 mae=0.118500 mse=0.020400 rmse=0.020400 r2=0.061700 
测试集 timing_ctrl: loss=0.038300 mae=0.174000 mse=0.038300 rmse=0.038300 r2=-0.209100 
测试集 array_128_32_8t: loss=0.014600 mae=0.099700 mse=0.014600 rmse=0.014600 r2=0.276400 

Epoch 126/200 - 训练: loss=0.013100 mae=0.083800 mse=0.013100 rmse=0.013100 r2=0.403800 
Epoch 126/200 - 验证: loss=0.017600 mae=0.112300 mse=0.017600 rmse=0.017600 r2=0.173500 
Epoch 127/200 - 训练: loss=0.013100 mae=0.083800 mse=0.013100 rmse=0.013100 r2=0.404600 
Epoch 127/200 - 验证: loss=0.018500 mae=0.116500 mse=0.018500 rmse=0.018500 r2=0.128700 
Epoch 128/200 - 训练: loss=0.013100 mae=0.083800 mse=0.013100 rmse=0.013100 r2=0.405800 
Epoch 128/200 - 验证: loss=0.016700 mae=0.108700 mse=0.016700 rmse=0.016700 r2=0.213300 
【新的最佳模型！】Epoch 128
测试集 digtime: loss=0.020200 mae=0.117500 mse=0.020200 rmse=0.020200 r2=0.067700 
测试集 timing_ctrl: loss=0.038000 mae=0.172100 mse=0.038000 rmse=0.038000 r2=-0.200300 
测试集 array_128_32_8t: loss=0.014200 mae=0.097100 mse=0.014200 rmse=0.014200 r2=0.295700 

Epoch 129/200 - 训练: loss=0.013100 mae=0.083900 mse=0.013100 rmse=0.013100 r2=0.403900 
Epoch 129/200 - 验证: loss=0.016700 mae=0.108500 mse=0.016700 rmse=0.016700 r2=0.214200 
【新的最佳模型！】Epoch 129
测试集 digtime: loss=0.019800 mae=0.116000 mse=0.019800 rmse=0.019800 r2=0.088800 
测试集 timing_ctrl: loss=0.037100 mae=0.169200 mse=0.037100 rmse=0.037100 r2=-0.172700 
测试集 array_128_32_8t: loss=0.014100 mae=0.096500 mse=0.014100 rmse=0.014100 r2=0.300100 

Epoch 130/200 - 训练: loss=0.013100 mae=0.083700 mse=0.013100 rmse=0.013100 r2=0.405000 
Epoch 130/200 - 验证: loss=0.017600 mae=0.111900 mse=0.017600 rmse=0.017600 r2=0.170400 
Epoch 131/200 - 训练: loss=0.013100 mae=0.083900 mse=0.013100 rmse=0.013100 r2=0.404500 
Epoch 131/200 - 验证: loss=0.017800 mae=0.113300 mse=0.017800 rmse=0.017800 r2=0.163900 
Epoch 132/200 - 训练: loss=0.013000 mae=0.083500 mse=0.013000 rmse=0.013000 r2=0.407100 
Epoch 132/200 - 验证: loss=0.016900 mae=0.109500 mse=0.016900 rmse=0.016900 r2=0.206000 
Epoch 133/200 - 训练: loss=0.013000 mae=0.083500 mse=0.013000 rmse=0.013000 r2=0.406200 
Epoch 133/200 - 验证: loss=0.018300 mae=0.116000 mse=0.018300 rmse=0.018300 r2=0.137100 
Epoch 134/200 - 训练: loss=0.013000 mae=0.083600 mse=0.013000 rmse=0.013000 r2=0.407400 
Epoch 134/200 - 验证: loss=0.017400 mae=0.111300 mse=0.017400 rmse=0.017400 r2=0.178900 
Epoch 135/200 - 训练: loss=0.013100 mae=0.083500 mse=0.013100 rmse=0.013100 r2=0.405400 
Epoch 135/200 - 验证: loss=0.017100 mae=0.110400 mse=0.017100 rmse=0.017100 r2=0.194000 
Epoch 136/200 - 训练: loss=0.013100 mae=0.083600 mse=0.013100 rmse=0.013100 r2=0.405300 
Epoch 136/200 - 验证: loss=0.016700 mae=0.108200 mse=0.016700 rmse=0.016700 r2=0.214800 
【新的最佳模型！】Epoch 136
测试集 digtime: loss=0.020000 mae=0.116800 mse=0.020000 rmse=0.020000 r2=0.080200 
测试集 timing_ctrl: loss=0.037500 mae=0.171000 mse=0.037500 rmse=0.037500 r2=-0.184100 
测试集 array_128_32_8t: loss=0.014300 mae=0.097200 mse=0.014300 rmse=0.014300 r2=0.292200 

Epoch 137/200 - 训练: loss=0.013000 mae=0.083600 mse=0.013000 rmse=0.013000 r2=0.409700 
Epoch 137/200 - 验证: loss=0.016900 mae=0.110000 mse=0.016900 rmse=0.016900 r2=0.204200 
Epoch 138/200 - 训练: loss=0.013000 mae=0.083600 mse=0.013000 rmse=0.013000 r2=0.406400 
Epoch 138/200 - 验证: loss=0.017100 mae=0.110900 mse=0.017100 rmse=0.017100 r2=0.196900 
Epoch 139/200 - 训练: loss=0.013000 mae=0.083700 mse=0.013000 rmse=0.013000 r2=0.406400 
Epoch 139/200 - 验证: loss=0.016600 mae=0.108300 mse=0.016600 rmse=0.016600 r2=0.220200 
【新的最佳模型！】Epoch 139
测试集 digtime: loss=0.019700 mae=0.115900 mse=0.019700 rmse=0.019700 r2=0.091300 
测试集 timing_ctrl: loss=0.036800 mae=0.168900 mse=0.036800 rmse=0.036800 r2=-0.161700 
测试集 array_128_32_8t: loss=0.014100 mae=0.096700 mse=0.014100 rmse=0.014100 r2=0.297900 

Epoch 140/200 - 训练: loss=0.013000 mae=0.083800 mse=0.013000 rmse=0.013000 r2=0.407900 
Epoch 140/200 - 验证: loss=0.017100 mae=0.109700 mse=0.017100 rmse=0.017100 r2=0.197500 
Epoch 141/200 - 训练: loss=0.013000 mae=0.083600 mse=0.013000 rmse=0.013000 r2=0.406100 
Epoch 141/200 - 验证: loss=0.017000 mae=0.110700 mse=0.017000 rmse=0.017000 r2=0.200000 
Epoch 142/200 - 训练: loss=0.013000 mae=0.083200 mse=0.013000 rmse=0.013000 r2=0.409400 
Epoch 142/200 - 验证: loss=0.017100 mae=0.109500 mse=0.017100 rmse=0.017100 r2=0.196400 
Epoch 143/200 - 训练: loss=0.013000 mae=0.083200 mse=0.013000 rmse=0.013000 r2=0.410000 
Epoch 143/200 - 验证: loss=0.017300 mae=0.111100 mse=0.017300 rmse=0.017300 r2=0.185700 
Epoch 144/200 - 训练: loss=0.013000 mae=0.083300 mse=0.013000 rmse=0.013000 r2=0.408200 
Epoch 144/200 - 验证: loss=0.016900 mae=0.110000 mse=0.016900 rmse=0.016900 r2=0.204800 
Epoch 145/200 - 训练: loss=0.012900 mae=0.082900 mse=0.012900 rmse=0.012900 r2=0.412000 
Epoch 145/200 - 验证: loss=0.016900 mae=0.109800 mse=0.016900 rmse=0.016900 r2=0.203800 
Epoch 146/200 - 训练: loss=0.012900 mae=0.083400 mse=0.012900 rmse=0.012900 r2=0.412500 
Epoch 146/200 - 验证: loss=0.016900 mae=0.109800 mse=0.016900 rmse=0.016900 r2=0.202500 
Epoch 147/200 - 训练: loss=0.013000 mae=0.083500 mse=0.013000 rmse=0.013000 r2=0.407000 
Epoch 147/200 - 验证: loss=0.017100 mae=0.110100 mse=0.017100 rmse=0.017100 r2=0.194700 
Epoch 148/200 - 训练: loss=0.013000 mae=0.083700 mse=0.013000 rmse=0.013000 r2=0.406100 
Epoch 148/200 - 验证: loss=0.016000 mae=0.105800 mse=0.016000 rmse=0.016000 r2=0.246500 
【新的最佳模型！】Epoch 148
测试集 digtime: loss=0.020000 mae=0.116400 mse=0.020000 rmse=0.020000 r2=0.078300 
测试集 timing_ctrl: loss=0.036800 mae=0.168800 mse=0.036800 rmse=0.036800 r2=-0.161300 
测试集 array_128_32_8t: loss=0.013900 mae=0.095400 mse=0.013900 rmse=0.013900 r2=0.309600 

Epoch 149/200 - 训练: loss=0.013000 mae=0.083600 mse=0.013000 rmse=0.013000 r2=0.407400 
Epoch 149/200 - 验证: loss=0.015900 mae=0.105100 mse=0.015900 rmse=0.015900 r2=0.253500 
【新的最佳模型！】Epoch 149
测试集 digtime: loss=0.019100 mae=0.113700 mse=0.019100 rmse=0.019100 r2=0.119700 
测试集 timing_ctrl: loss=0.035200 mae=0.165300 mse=0.035200 rmse=0.035200 r2=-0.112100 
测试集 array_128_32_8t: loss=0.013700 mae=0.093700 mse=0.013700 rmse=0.013700 r2=0.319100 

Epoch 150/200 - 训练: loss=0.012900 mae=0.083200 mse=0.012900 rmse=0.012900 r2=0.410900 
Epoch 150/200 - 验证: loss=0.017000 mae=0.110400 mse=0.017000 rmse=0.017000 r2=0.201200 
Epoch 151/200 - 训练: loss=0.012900 mae=0.083100 mse=0.012900 rmse=0.012900 r2=0.412300 
Epoch 151/200 - 验证: loss=0.017000 mae=0.108400 mse=0.017000 rmse=0.017000 r2=0.201700 
Epoch 152/200 - 训练: loss=0.013000 mae=0.083400 mse=0.013000 rmse=0.013000 r2=0.410400 
Epoch 152/200 - 验证: loss=0.016500 mae=0.107700 mse=0.016500 rmse=0.016500 r2=0.224700 
Epoch 153/200 - 训练: loss=0.013000 mae=0.083400 mse=0.013000 rmse=0.013000 r2=0.410100 
Epoch 153/200 - 验证: loss=0.016900 mae=0.110000 mse=0.016900 rmse=0.016900 r2=0.205000 
Epoch 154/200 - 训练: loss=0.012900 mae=0.083200 mse=0.012900 rmse=0.012900 r2=0.412900 
Epoch 154/200 - 验证: loss=0.016300 mae=0.107000 mse=0.016300 rmse=0.016300 r2=0.232200 
Epoch 155/200 - 训练: loss=0.012900 mae=0.083000 mse=0.012900 rmse=0.012900 r2=0.410800 
Epoch 155/200 - 验证: loss=0.016400 mae=0.107600 mse=0.016400 rmse=0.016400 r2=0.225900 
Epoch 156/200 - 训练: loss=0.012900 mae=0.083200 mse=0.012900 rmse=0.012900 r2=0.410500 
Epoch 156/200 - 验证: loss=0.015300 mae=0.102700 mse=0.015300 rmse=0.015300 r2=0.277600 
【新的最佳模型！】Epoch 156
测试集 digtime: loss=0.018500 mae=0.112200 mse=0.018500 rmse=0.018500 r2=0.146200 
测试集 timing_ctrl: loss=0.034100 mae=0.162700 mse=0.034100 rmse=0.034100 r2=-0.077600 
测试集 array_128_32_8t: loss=0.013400 mae=0.090900 mse=0.013400 rmse=0.013400 r2=0.336000 

Epoch 157/200 - 训练: loss=0.013000 mae=0.083200 mse=0.013000 rmse=0.013000 r2=0.410000 
Epoch 157/200 - 验证: loss=0.016000 mae=0.105500 mse=0.016000 rmse=0.016000 r2=0.244700 
Epoch 158/200 - 训练: loss=0.012900 mae=0.083100 mse=0.012900 rmse=0.012900 r2=0.412200 
Epoch 158/200 - 验证: loss=0.016400 mae=0.107700 mse=0.016400 rmse=0.016400 r2=0.229500 
Epoch 159/200 - 训练: loss=0.012900 mae=0.083200 mse=0.012900 rmse=0.012900 r2=0.412100 
Epoch 159/200 - 验证: loss=0.015200 mae=0.101900 mse=0.015200 rmse=0.015200 r2=0.282300 
【新的最佳模型！】Epoch 159
测试集 digtime: loss=0.018400 mae=0.111300 mse=0.018400 rmse=0.018400 r2=0.149900 
测试集 timing_ctrl: loss=0.033800 mae=0.161300 mse=0.033800 rmse=0.033800 r2=-0.067700 
测试集 array_128_32_8t: loss=0.013300 mae=0.090500 mse=0.013300 rmse=0.013300 r2=0.341200 

Epoch 160/200 - 训练: loss=0.012900 mae=0.083000 mse=0.012900 rmse=0.012900 r2=0.413500 
Epoch 160/200 - 验证: loss=0.016600 mae=0.108400 mse=0.016600 rmse=0.016600 r2=0.217800 
Epoch 161/200 - 训练: loss=0.012900 mae=0.083000 mse=0.012900 rmse=0.012900 r2=0.412300 
Epoch 161/200 - 验证: loss=0.016200 mae=0.106100 mse=0.016200 rmse=0.016200 r2=0.239600 
Epoch 162/200 - 训练: loss=0.012900 mae=0.082900 mse=0.012900 rmse=0.012900 r2=0.412800 
Epoch 162/200 - 验证: loss=0.016300 mae=0.107000 mse=0.016300 rmse=0.016300 r2=0.232700 
Epoch 163/200 - 训练: loss=0.012900 mae=0.082900 mse=0.012900 rmse=0.012900 r2=0.413500 
Epoch 163/200 - 验证: loss=0.015600 mae=0.103800 mse=0.015600 rmse=0.015600 r2=0.266100 
Epoch 164/200 - 训练: loss=0.012900 mae=0.083000 mse=0.012900 rmse=0.012900 r2=0.414900 
Epoch 164/200 - 验证: loss=0.016800 mae=0.109400 mse=0.016800 rmse=0.016800 r2=0.209000 
Epoch 165/200 - 训练: loss=0.013000 mae=0.083100 mse=0.013000 rmse=0.013000 r2=0.409000 
Epoch 165/200 - 验证: loss=0.015400 mae=0.102600 mse=0.015400 rmse=0.015400 r2=0.275300 
Epoch 166/200 - 训练: loss=0.012900 mae=0.083000 mse=0.012900 rmse=0.012900 r2=0.413400 
Epoch 166/200 - 验证: loss=0.016000 mae=0.105800 mse=0.016000 rmse=0.016000 r2=0.249100 
Epoch 167/200 - 训练: loss=0.012900 mae=0.083200 mse=0.012900 rmse=0.012900 r2=0.412800 
Epoch 167/200 - 验证: loss=0.016900 mae=0.109400 mse=0.016900 rmse=0.016900 r2=0.206000 
Epoch 168/200 - 训练: loss=0.012800 mae=0.082700 mse=0.012800 rmse=0.012800 r2=0.417200 
Epoch 168/200 - 验证: loss=0.015500 mae=0.103600 mse=0.015500 rmse=0.015500 r2=0.270300 
Epoch 169/200 - 训练: loss=0.012900 mae=0.082800 mse=0.012900 rmse=0.012900 r2=0.411200 
Epoch 169/200 - 验证: loss=0.016000 mae=0.106700 mse=0.016000 rmse=0.016000 r2=0.244600 
Epoch 170/200 - 训练: loss=0.012800 mae=0.082600 mse=0.012800 rmse=0.012800 r2=0.416400 
Epoch 170/200 - 验证: loss=0.015400 mae=0.103000 mse=0.015400 rmse=0.015400 r2=0.277300 
Epoch 171/200 - 训练: loss=0.012800 mae=0.082800 mse=0.012800 rmse=0.012800 r2=0.417500 
Epoch 171/200 - 验证: loss=0.016300 mae=0.107300 mse=0.016300 rmse=0.016300 r2=0.230700 
Epoch 172/200 - 训练: loss=0.012800 mae=0.082800 mse=0.012800 rmse=0.012800 r2=0.416000 
Epoch 172/200 - 验证: loss=0.015600 mae=0.103600 mse=0.015600 rmse=0.015600 r2=0.264100 
Epoch 173/200 - 训练: loss=0.012900 mae=0.083100 mse=0.012900 rmse=0.012900 r2=0.412100 
Epoch 173/200 - 验证: loss=0.015200 mae=0.102000 mse=0.015200 rmse=0.015200 r2=0.286300 
【新的最佳模型！】Epoch 173
测试集 digtime: loss=0.018200 mae=0.109800 mse=0.018200 rmse=0.018200 r2=0.162200 
测试集 timing_ctrl: loss=0.033000 mae=0.159100 mse=0.033000 rmse=0.033000 r2=-0.042100 
测试集 array_128_32_8t: loss=0.013200 mae=0.090600 mse=0.013200 rmse=0.013200 r2=0.345500 

Epoch 174/200 - 训练: loss=0.012900 mae=0.082800 mse=0.012900 rmse=0.012900 r2=0.413800 
Epoch 174/200 - 验证: loss=0.016200 mae=0.107500 mse=0.016200 rmse=0.016200 r2=0.235900 
Epoch 175/200 - 训练: loss=0.012900 mae=0.083400 mse=0.012900 rmse=0.012900 r2=0.411100 
Epoch 175/200 - 验证: loss=0.015800 mae=0.105000 mse=0.015800 rmse=0.015800 r2=0.255300 
Epoch 176/200 - 训练: loss=0.012900 mae=0.082700 mse=0.012900 rmse=0.012900 r2=0.414000 
Epoch 176/200 - 验证: loss=0.015300 mae=0.102600 mse=0.015300 rmse=0.015300 r2=0.280300 
Epoch 177/200 - 训练: loss=0.012900 mae=0.083400 mse=0.012900 rmse=0.012900 r2=0.410600 
Epoch 177/200 - 验证: loss=0.015600 mae=0.103700 mse=0.015600 rmse=0.015600 r2=0.264200 
Epoch 178/200 - 训练: loss=0.012900 mae=0.083100 mse=0.012900 rmse=0.012900 r2=0.412500 
Epoch 178/200 - 验证: loss=0.014500 mae=0.098600 mse=0.014500 rmse=0.014500 r2=0.316200 
【新的最佳模型！】Epoch 178
测试集 digtime: loss=0.017800 mae=0.108300 mse=0.017800 rmse=0.017800 r2=0.178600 
测试集 timing_ctrl: loss=0.031900 mae=0.156400 mse=0.031900 rmse=0.031900 r2=-0.007300 
测试集 array_128_32_8t: loss=0.012800 mae=0.087700 mse=0.012800 rmse=0.012800 r2=0.362300 

Epoch 179/200 - 训练: loss=0.012900 mae=0.082800 mse=0.012900 rmse=0.012900 r2=0.414200 
Epoch 179/200 - 验证: loss=0.015100 mae=0.101500 mse=0.015100 rmse=0.015100 r2=0.289600 
Epoch 180/200 - 训练: loss=0.012900 mae=0.082800 mse=0.012900 rmse=0.012900 r2=0.414700 
Epoch 180/200 - 验证: loss=0.015000 mae=0.100500 mse=0.015000 rmse=0.015000 r2=0.294600 
Epoch 181/200 - 训练: loss=0.012800 mae=0.082500 mse=0.012800 rmse=0.012800 r2=0.418600 
Epoch 181/200 - 验证: loss=0.015400 mae=0.103100 mse=0.015400 rmse=0.015400 r2=0.274500 
Epoch 182/200 - 训练: loss=0.012700 mae=0.082500 mse=0.012700 rmse=0.012700 r2=0.419600 
Epoch 182/200 - 验证: loss=0.015900 mae=0.105800 mse=0.015900 rmse=0.015900 r2=0.250900 
Epoch 183/200 - 训练: loss=0.012900 mae=0.083000 mse=0.012900 rmse=0.012900 r2=0.412800 
Epoch 183/200 - 验证: loss=0.014600 mae=0.098800 mse=0.014600 rmse=0.014600 r2=0.314800 
Epoch 184/200 - 训练: loss=0.012900 mae=0.082700 mse=0.012900 rmse=0.012900 r2=0.413800 
Epoch 184/200 - 验证: loss=0.015300 mae=0.102800 mse=0.015300 rmse=0.015300 r2=0.279300 
Epoch 185/200 - 训练: loss=0.012800 mae=0.082800 mse=0.012800 rmse=0.012800 r2=0.415200 
Epoch 185/200 - 验证: loss=0.015000 mae=0.101200 mse=0.015000 rmse=0.015000 r2=0.293200 
Epoch 186/200 - 训练: loss=0.012800 mae=0.082800 mse=0.012800 rmse=0.012800 r2=0.416700 
Epoch 186/200 - 验证: loss=0.015000 mae=0.101300 mse=0.015000 rmse=0.015000 r2=0.293100 
Epoch 187/200 - 训练: loss=0.012800 mae=0.082800 mse=0.012800 rmse=0.012800 r2=0.416100 
Epoch 187/200 - 验证: loss=0.014600 mae=0.098800 mse=0.014600 rmse=0.014600 r2=0.311500 
Epoch 188/200 - 训练: loss=0.012900 mae=0.082800 mse=0.012900 rmse=0.012900 r2=0.414300 
Epoch 188/200 - 验证: loss=0.015200 mae=0.102100 mse=0.015200 rmse=0.015200 r2=0.283000 
Epoch 189/200 - 训练: loss=0.012900 mae=0.082700 mse=0.012900 rmse=0.012900 r2=0.414100 
Epoch 189/200 - 验证: loss=0.015000 mae=0.101000 mse=0.015000 rmse=0.015000 r2=0.293500 
Epoch 190/200 - 训练: loss=0.012800 mae=0.082800 mse=0.012800 rmse=0.012800 r2=0.415500 
Epoch 190/200 - 验证: loss=0.015400 mae=0.102900 mse=0.015400 rmse=0.015400 r2=0.274800 
Epoch 191/200 - 训练: loss=0.012900 mae=0.082700 mse=0.012900 rmse=0.012900 r2=0.415000 
Epoch 191/200 - 验证: loss=0.015700 mae=0.103800 mse=0.015700 rmse=0.015700 r2=0.261300 
Epoch 192/200 - 训练: loss=0.012800 mae=0.082600 mse=0.012800 rmse=0.012800 r2=0.418300 
Epoch 192/200 - 验证: loss=0.015000 mae=0.100200 mse=0.015000 rmse=0.015000 r2=0.294900 
Epoch 193/200 - 训练: loss=0.012800 mae=0.082500 mse=0.012800 rmse=0.012800 r2=0.418000 
Epoch 193/200 - 验证: loss=0.015100 mae=0.101700 mse=0.015100 rmse=0.015100 r2=0.288500 
Epoch 194/200 - 训练: loss=0.012800 mae=0.082500 mse=0.012800 rmse=0.012800 r2=0.418700 
Epoch 194/200 - 验证: loss=0.014800 mae=0.100000 mse=0.014800 rmse=0.014800 r2=0.303700 
Epoch 195/200 - 训练: loss=0.012800 mae=0.082600 mse=0.012800 rmse=0.012800 r2=0.417800 
Epoch 195/200 - 验证: loss=0.015000 mae=0.101400 mse=0.015000 rmse=0.015000 r2=0.292500 
Epoch 196/200 - 训练: loss=0.012700 mae=0.082200 mse=0.012700 rmse=0.012700 r2=0.422200 
Epoch 196/200 - 验证: loss=0.015600 mae=0.104100 mse=0.015600 rmse=0.015600 r2=0.264400 
Epoch 197/200 - 训练: loss=0.012800 mae=0.082600 mse=0.012800 rmse=0.012800 r2=0.416800 
Epoch 197/200 - 验证: loss=0.015000 mae=0.100400 mse=0.015000 rmse=0.015000 r2=0.294800 
Epoch 198/200 - 训练: loss=0.012900 mae=0.082800 mse=0.012900 rmse=0.012900 r2=0.412600 
Epoch 198/200 - 验证: loss=0.014400 mae=0.097900 mse=0.014400 rmse=0.014400 r2=0.320700 
【新的最佳模型！】Epoch 198
测试集 digtime: loss=0.016800 mae=0.103200 mse=0.016800 rmse=0.016800 r2=0.226900 
测试集 timing_ctrl: loss=0.029700 mae=0.152200 mse=0.029700 rmse=0.029700 r2=0.060800 
测试集 array_128_32_8t: loss=0.012500 mae=0.085400 mse=0.012500 rmse=0.012500 r2=0.378200 

Epoch 199/200 - 训练: loss=0.012800 mae=0.082600 mse=0.012800 rmse=0.012800 r2=0.416500 
Epoch 199/200 - 验证: loss=0.015100 mae=0.101600 mse=0.015100 rmse=0.015100 r2=0.290700 
Epoch 200/200 - 训练: loss=0.012800 mae=0.082700 mse=0.012800 rmse=0.012800 r2=0.417300 
Epoch 200/200 - 验证: loss=0.014600 mae=0.098600 mse=0.014600 rmse=0.014600 r2=0.313100 

训练完成!
最佳模型在第 198 轮, 验证R2 = 0.320700, 验证损失 = 0.014400
