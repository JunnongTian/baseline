Paragraph-Simple 训练日志
数据集: ssram
训练参数: {'train_dataset': 'ssram', 'test_dataset': 'digtime+timing_ctrl+array_128_32_8t', 'task': 'regression', 'max_dist': 350, 'lr': 5e-05, 'num_gnn_layers': 4, 'num_head_layers': 2, 'hid_dim': 64, 'dropout': 0.3, 'use_bn': 1, 'act_fn': 'relu', 'src_dst_agg': 'concat', 'num_hops': 4, 'to_undirected': 1, 'train_sample_rate': 0.1, 'test_sample_rate': 1.0, 'use_ensemble': 0, 'num_ensemble': 3, 'ensemble_thresholds': '0.33,0.66'}

Epoch 1/200 - 训练: loss=0.097900 mae=0.247500 mse=0.097900 rmse=0.097900 r2=-3.459000 
Epoch 1/200 - 验证: loss=0.049500 mae=0.180900 mse=0.049500 rmse=0.049500 r2=-1.327800 
【新的最佳模型！】Epoch 1
测试集 digtime: loss=0.051200 mae=0.186800 mse=0.051200 rmse=0.051200 r2=-1.361700 
测试集 timing_ctrl: loss=0.081100 mae=0.219600 mse=0.081100 rmse=0.081100 r2=-1.560900 
测试集 array_128_32_8t: loss=0.047200 mae=0.173000 mse=0.047200 rmse=0.047200 r2=-1.345700 

Epoch 2/200 - 训练: loss=0.045700 mae=0.169500 mse=0.045700 rmse=0.045700 r2=-1.080800 
Epoch 2/200 - 验证: loss=0.035500 mae=0.157300 mse=0.035500 rmse=0.035500 r2=-0.671300 
【新的最佳模型！】Epoch 2
测试集 digtime: loss=0.040600 mae=0.171400 mse=0.040600 rmse=0.040600 r2=-0.870600 
测试集 timing_ctrl: loss=0.059200 mae=0.196200 mse=0.059200 rmse=0.059200 r2=-0.871400 
测试集 array_128_32_8t: loss=0.032000 mae=0.146000 mse=0.032000 rmse=0.032000 r2=-0.588400 

Epoch 3/200 - 训练: loss=0.037300 mae=0.152400 mse=0.037300 rmse=0.037300 r2=-0.698300 
Epoch 3/200 - 验证: loss=0.047100 mae=0.185400 mse=0.047100 rmse=0.047100 r2=-1.216800 
Epoch 4/200 - 训练: loss=0.032400 mae=0.141900 mse=0.032400 rmse=0.032400 r2=-0.475600 
Epoch 4/200 - 验证: loss=0.047900 mae=0.188000 mse=0.047900 rmse=0.047900 r2=-1.252500 
Epoch 5/200 - 训练: loss=0.029500 mae=0.134900 mse=0.029500 rmse=0.029500 r2=-0.343800 
Epoch 5/200 - 验证: loss=0.038300 mae=0.171300 mse=0.038300 rmse=0.038300 r2=-0.803300 
Epoch 6/200 - 训练: loss=0.026300 mae=0.127500 mse=0.026300 rmse=0.026300 r2=-0.198500 
Epoch 6/200 - 验证: loss=0.031500 mae=0.152300 mse=0.031500 rmse=0.031500 r2=-0.484300 
【新的最佳模型！】Epoch 6
测试集 digtime: loss=0.035300 mae=0.156300 mse=0.035300 rmse=0.035300 r2=-0.625800 
测试集 timing_ctrl: loss=0.049200 mae=0.200500 mse=0.049200 rmse=0.049200 r2=-0.555300 
测试集 array_128_32_8t: loss=0.024500 mae=0.137200 mse=0.024500 rmse=0.024500 r2=-0.216300 

Epoch 7/200 - 训练: loss=0.025100 mae=0.123700 mse=0.025100 rmse=0.025100 r2=-0.142700 
Epoch 7/200 - 验证: loss=0.034100 mae=0.160400 mse=0.034100 rmse=0.034100 r2=-0.604900 
Epoch 8/200 - 训练: loss=0.023000 mae=0.118100 mse=0.023000 rmse=0.023000 r2=-0.049200 
Epoch 8/200 - 验证: loss=0.032900 mae=0.151100 mse=0.032900 rmse=0.032900 r2=-0.550300 
Epoch 9/200 - 训练: loss=0.021600 mae=0.114200 mse=0.021600 rmse=0.021600 r2=0.017100 
Epoch 9/200 - 验证: loss=0.037300 mae=0.156800 mse=0.037300 rmse=0.037300 r2=-0.753700 
Epoch 10/200 - 训练: loss=0.020300 mae=0.110200 mse=0.020300 rmse=0.020300 r2=0.075900 
Epoch 10/200 - 验证: loss=0.032900 mae=0.155900 mse=0.032900 rmse=0.032900 r2=-0.547000 
Epoch 11/200 - 训练: loss=0.019400 mae=0.107900 mse=0.019400 rmse=0.019400 r2=0.117100 
Epoch 11/200 - 验证: loss=0.032700 mae=0.158100 mse=0.032700 rmse=0.032700 r2=-0.537600 
Epoch 12/200 - 训练: loss=0.019000 mae=0.106200 mse=0.019000 rmse=0.019000 r2=0.134200 
Epoch 12/200 - 验证: loss=0.027200 mae=0.141600 mse=0.027200 rmse=0.027200 r2=-0.279100 
【新的最佳模型！】Epoch 12
测试集 digtime: loss=0.024900 mae=0.137100 mse=0.024900 rmse=0.024900 r2=-0.149800 
测试集 timing_ctrl: loss=0.043600 mae=0.195100 mse=0.043600 rmse=0.043600 r2=-0.376000 
测试集 array_128_32_8t: loss=0.024700 mae=0.136000 mse=0.024700 rmse=0.024700 r2=-0.225100 

Epoch 13/200 - 训练: loss=0.018500 mae=0.104900 mse=0.018500 rmse=0.018500 r2=0.157400 
Epoch 13/200 - 验证: loss=0.024600 mae=0.131600 mse=0.024600 rmse=0.024600 r2=-0.156700 
【新的最佳模型！】Epoch 13
测试集 digtime: loss=0.023600 mae=0.131400 mse=0.023600 rmse=0.023600 r2=-0.088700 
测试集 timing_ctrl: loss=0.039700 mae=0.186100 mse=0.039700 rmse=0.039700 r2=-0.252700 
测试集 array_128_32_8t: loss=0.022200 mae=0.124800 mse=0.022200 rmse=0.022200 r2=-0.101800 

Epoch 14/200 - 训练: loss=0.017600 mae=0.101600 mse=0.017600 rmse=0.017600 r2=0.198000 
Epoch 14/200 - 验证: loss=0.022000 mae=0.124000 mse=0.022000 rmse=0.022000 r2=-0.034100 
【新的最佳模型！】Epoch 14
测试集 digtime: loss=0.021200 mae=0.123800 mse=0.021200 rmse=0.021200 r2=0.024500 
测试集 timing_ctrl: loss=0.036900 mae=0.179600 mse=0.036900 rmse=0.036900 r2=-0.165300 
测试集 array_128_32_8t: loss=0.019700 mae=0.117300 mse=0.019700 rmse=0.019700 r2=0.019700 

Epoch 15/200 - 训练: loss=0.017200 mae=0.100400 mse=0.017200 rmse=0.017200 r2=0.216400 
Epoch 15/200 - 验证: loss=0.028000 mae=0.142900 mse=0.028000 rmse=0.028000 r2=-0.319400 
Epoch 16/200 - 训练: loss=0.017100 mae=0.100000 mse=0.017100 rmse=0.017100 r2=0.222900 
Epoch 16/200 - 验证: loss=0.022000 mae=0.120900 mse=0.022000 rmse=0.022000 r2=-0.034500 
Epoch 17/200 - 训练: loss=0.016800 mae=0.098700 mse=0.016800 rmse=0.016800 r2=0.234600 
Epoch 17/200 - 验证: loss=0.028200 mae=0.144400 mse=0.028200 rmse=0.028200 r2=-0.327400 
Epoch 18/200 - 训练: loss=0.016500 mae=0.097800 mse=0.016500 rmse=0.016500 r2=0.248500 
Epoch 18/200 - 验证: loss=0.019600 mae=0.116000 mse=0.019600 rmse=0.019600 r2=0.078000 
【新的最佳模型！】Epoch 18
测试集 digtime: loss=0.019600 mae=0.118100 mse=0.019600 rmse=0.019600 r2=0.095600 
测试集 timing_ctrl: loss=0.035200 mae=0.176000 mse=0.035200 rmse=0.035200 r2=-0.112800 
测试集 array_128_32_8t: loss=0.017800 mae=0.110300 mse=0.017800 rmse=0.017800 r2=0.117500 

Epoch 19/200 - 训练: loss=0.016500 mae=0.097400 mse=0.016500 rmse=0.016500 r2=0.250900 
Epoch 19/200 - 验证: loss=0.020600 mae=0.120900 mse=0.020600 rmse=0.020600 r2=0.028900 
Epoch 20/200 - 训练: loss=0.016200 mae=0.096300 mse=0.016200 rmse=0.016200 r2=0.264400 
Epoch 20/200 - 验证: loss=0.022600 mae=0.128000 mse=0.022600 rmse=0.022600 r2=-0.064000 
Epoch 21/200 - 训练: loss=0.015900 mae=0.095300 mse=0.015900 rmse=0.015900 r2=0.278000 
Epoch 21/200 - 验证: loss=0.019700 mae=0.114800 mse=0.019700 rmse=0.019700 r2=0.071100 
Epoch 22/200 - 训练: loss=0.015800 mae=0.095000 mse=0.015800 rmse=0.015800 r2=0.281500 
Epoch 22/200 - 验证: loss=0.020800 mae=0.121100 mse=0.020800 rmse=0.020800 r2=0.022200 
Epoch 23/200 - 训练: loss=0.015500 mae=0.094500 mse=0.015500 rmse=0.015500 r2=0.292700 
Epoch 23/200 - 验证: loss=0.019200 mae=0.114800 mse=0.019200 rmse=0.019200 r2=0.098400 
【新的最佳模型！】Epoch 23
测试集 digtime: loss=0.019900 mae=0.119100 mse=0.019900 rmse=0.019900 r2=0.080700 
测试集 timing_ctrl: loss=0.035400 mae=0.176400 mse=0.035400 rmse=0.035400 r2=-0.118200 
测试集 array_128_32_8t: loss=0.017400 mae=0.109200 mse=0.017400 rmse=0.017400 r2=0.133300 

Epoch 24/200 - 训练: loss=0.015700 mae=0.094600 mse=0.015700 rmse=0.015700 r2=0.286700 
Epoch 24/200 - 验证: loss=0.019700 mae=0.117400 mse=0.019700 rmse=0.019700 r2=0.070500 
Epoch 25/200 - 训练: loss=0.015500 mae=0.094100 mse=0.015500 rmse=0.015500 r2=0.294900 
Epoch 25/200 - 验证: loss=0.019600 mae=0.115000 mse=0.019600 rmse=0.019600 r2=0.078800 
Epoch 26/200 - 训练: loss=0.015400 mae=0.093500 mse=0.015400 rmse=0.015400 r2=0.300000 
Epoch 26/200 - 验证: loss=0.018200 mae=0.109100 mse=0.018200 rmse=0.018200 r2=0.143900 
【新的最佳模型！】Epoch 26
测试集 digtime: loss=0.019100 mae=0.114800 mse=0.019100 rmse=0.019100 r2=0.120300 
测试集 timing_ctrl: loss=0.032800 mae=0.169600 mse=0.032800 rmse=0.032800 r2=-0.035400 
测试集 array_128_32_8t: loss=0.016500 mae=0.102900 mse=0.016500 rmse=0.016500 r2=0.179100 

Epoch 27/200 - 训练: loss=0.015300 mae=0.093100 mse=0.015300 rmse=0.015300 r2=0.304800 
Epoch 27/200 - 验证: loss=0.017600 mae=0.106600 mse=0.017600 rmse=0.017600 r2=0.172900 
【新的最佳模型！】Epoch 27
测试集 digtime: loss=0.018700 mae=0.113400 mse=0.018700 rmse=0.018700 r2=0.136600 
测试集 timing_ctrl: loss=0.031900 mae=0.167300 mse=0.031900 rmse=0.031900 r2=-0.009200 
测试集 array_128_32_8t: loss=0.015900 mae=0.100300 mse=0.015900 rmse=0.015900 r2=0.208500 

Epoch 28/200 - 训练: loss=0.015300 mae=0.093300 mse=0.015300 rmse=0.015300 r2=0.301700 
Epoch 28/200 - 验证: loss=0.018000 mae=0.110100 mse=0.018000 rmse=0.018000 r2=0.152800 
Epoch 29/200 - 训练: loss=0.015200 mae=0.092500 mse=0.015200 rmse=0.015200 r2=0.310300 
Epoch 29/200 - 验证: loss=0.017400 mae=0.104800 mse=0.017400 rmse=0.017400 r2=0.182200 
【新的最佳模型！】Epoch 29
测试集 digtime: loss=0.018600 mae=0.112600 mse=0.018600 rmse=0.018600 r2=0.144000 
测试集 timing_ctrl: loss=0.030600 mae=0.163500 mse=0.030600 rmse=0.030600 r2=0.033100 
测试集 array_128_32_8t: loss=0.015800 mae=0.098900 mse=0.015800 rmse=0.015800 r2=0.215800 

Epoch 30/200 - 训练: loss=0.015100 mae=0.092200 mse=0.015100 rmse=0.015100 r2=0.311500 
Epoch 30/200 - 验证: loss=0.017000 mae=0.105600 mse=0.017000 rmse=0.017000 r2=0.197500 
【新的最佳模型！】Epoch 30
测试集 digtime: loss=0.018000 mae=0.111000 mse=0.018000 rmse=0.018000 r2=0.170400 
测试集 timing_ctrl: loss=0.031900 mae=0.166900 mse=0.031900 rmse=0.031900 r2=-0.007900 
测试集 array_128_32_8t: loss=0.015600 mae=0.099900 mse=0.015600 rmse=0.015600 r2=0.226200 

Epoch 31/200 - 训练: loss=0.015000 mae=0.092100 mse=0.015000 rmse=0.015000 r2=0.315500 
Epoch 31/200 - 验证: loss=0.016700 mae=0.104500 mse=0.016700 rmse=0.016700 r2=0.214400 
【新的最佳模型！】Epoch 31
测试集 digtime: loss=0.017600 mae=0.109700 mse=0.017600 rmse=0.017600 r2=0.188500 
测试集 timing_ctrl: loss=0.031700 mae=0.166000 mse=0.031700 rmse=0.031700 r2=-0.001300 
测试集 array_128_32_8t: loss=0.015200 mae=0.099000 mse=0.015200 rmse=0.015200 r2=0.242700 

Epoch 32/200 - 训练: loss=0.014900 mae=0.091700 mse=0.014900 rmse=0.014900 r2=0.321400 
Epoch 32/200 - 验证: loss=0.017000 mae=0.104700 mse=0.017000 rmse=0.017000 r2=0.200100 
Epoch 33/200 - 训练: loss=0.014900 mae=0.091300 mse=0.014900 rmse=0.014900 r2=0.322500 
Epoch 33/200 - 验证: loss=0.016400 mae=0.103500 mse=0.016400 rmse=0.016400 r2=0.227300 
【新的最佳模型！】Epoch 33
测试集 digtime: loss=0.017400 mae=0.108800 mse=0.017400 rmse=0.017400 r2=0.199100 
测试集 timing_ctrl: loss=0.031600 mae=0.165200 mse=0.031600 rmse=0.031600 r2=0.001800 
测试集 array_128_32_8t: loss=0.015000 mae=0.098100 mse=0.015000 rmse=0.015000 r2=0.254200 

Epoch 34/200 - 训练: loss=0.014600 mae=0.090500 mse=0.014600 rmse=0.014600 r2=0.333300 
Epoch 34/200 - 验证: loss=0.015800 mae=0.099900 mse=0.015800 rmse=0.015800 r2=0.258300 
【新的最佳模型！】Epoch 34
测试集 digtime: loss=0.016800 mae=0.105600 mse=0.016800 rmse=0.016800 r2=0.224400 
测试集 timing_ctrl: loss=0.030200 mae=0.161200 mse=0.030200 rmse=0.030200 r2=0.046800 
测试集 array_128_32_8t: loss=0.014400 mae=0.094300 mse=0.014400 rmse=0.014400 r2=0.283900 

Epoch 35/200 - 训练: loss=0.014700 mae=0.090800 mse=0.014700 rmse=0.014700 r2=0.329100 
Epoch 35/200 - 验证: loss=0.016400 mae=0.101600 mse=0.016400 rmse=0.016400 r2=0.229200 
Epoch 36/200 - 训练: loss=0.014700 mae=0.090900 mse=0.014700 rmse=0.014700 r2=0.330000 
Epoch 36/200 - 验证: loss=0.016500 mae=0.103600 mse=0.016500 rmse=0.016500 r2=0.221200 
Epoch 37/200 - 训练: loss=0.014500 mae=0.090200 mse=0.014500 rmse=0.014500 r2=0.339100 
Epoch 37/200 - 验证: loss=0.016000 mae=0.101400 mse=0.016000 rmse=0.016000 r2=0.245000 
Epoch 38/200 - 训练: loss=0.014400 mae=0.089700 mse=0.014400 rmse=0.014400 r2=0.343800 
Epoch 38/200 - 验证: loss=0.016900 mae=0.104900 mse=0.016900 rmse=0.016900 r2=0.205300 
Epoch 39/200 - 训练: loss=0.014500 mae=0.090100 mse=0.014500 rmse=0.014500 r2=0.341900 
Epoch 39/200 - 验证: loss=0.016000 mae=0.100700 mse=0.016000 rmse=0.016000 r2=0.247000 
Epoch 40/200 - 训练: loss=0.014500 mae=0.090200 mse=0.014500 rmse=0.014500 r2=0.339800 
Epoch 40/200 - 验证: loss=0.015900 mae=0.100000 mse=0.015900 rmse=0.015900 r2=0.251600 
Epoch 41/200 - 训练: loss=0.014500 mae=0.089800 mse=0.014500 rmse=0.014500 r2=0.342100 
Epoch 41/200 - 验证: loss=0.015300 mae=0.095800 mse=0.015300 rmse=0.015300 r2=0.282100 
【新的最佳模型！】Epoch 41
测试集 digtime: loss=0.016400 mae=0.103400 mse=0.016400 rmse=0.016400 r2=0.242000 
测试集 timing_ctrl: loss=0.027700 mae=0.154600 mse=0.027700 rmse=0.027700 r2=0.125600 
测试集 array_128_32_8t: loss=0.014000 mae=0.090400 mse=0.014000 rmse=0.014000 r2=0.305000 

Epoch 42/200 - 训练: loss=0.014400 mae=0.090000 mse=0.014400 rmse=0.014400 r2=0.343200 
Epoch 42/200 - 验证: loss=0.015100 mae=0.096200 mse=0.015100 rmse=0.015100 r2=0.290100 
【新的最佳模型！】Epoch 42
测试集 digtime: loss=0.016200 mae=0.102600 mse=0.016200 rmse=0.016200 r2=0.252000 
测试集 timing_ctrl: loss=0.028900 mae=0.155900 mse=0.028900 rmse=0.028900 r2=0.085500 
测试集 array_128_32_8t: loss=0.013800 mae=0.090100 mse=0.013800 rmse=0.013800 r2=0.316800 

Epoch 43/200 - 训练: loss=0.014200 mae=0.088800 mse=0.014200 rmse=0.014200 r2=0.353000 
Epoch 43/200 - 验证: loss=0.015000 mae=0.094700 mse=0.015000 rmse=0.015000 r2=0.295700 
【新的最佳模型！】Epoch 43
测试集 digtime: loss=0.016600 mae=0.103700 mse=0.016600 rmse=0.016600 r2=0.236600 
测试集 timing_ctrl: loss=0.026900 mae=0.152300 mse=0.026900 rmse=0.026900 r2=0.148700 
测试集 array_128_32_8t: loss=0.013600 mae=0.088800 mse=0.013600 rmse=0.013600 r2=0.322100 

Epoch 44/200 - 训练: loss=0.014400 mae=0.089800 mse=0.014400 rmse=0.014400 r2=0.344800 
Epoch 44/200 - 验证: loss=0.016000 mae=0.099900 mse=0.016000 rmse=0.016000 r2=0.246300 
Epoch 45/200 - 训练: loss=0.014400 mae=0.089400 mse=0.014400 rmse=0.014400 r2=0.346300 
Epoch 45/200 - 验证: loss=0.015200 mae=0.097100 mse=0.015200 rmse=0.015200 r2=0.283700 
Epoch 46/200 - 训练: loss=0.014100 mae=0.088300 mse=0.014100 rmse=0.014100 r2=0.359400 
Epoch 46/200 - 验证: loss=0.014500 mae=0.092500 mse=0.014500 rmse=0.014500 r2=0.319600 
【新的最佳模型！】Epoch 46
测试集 digtime: loss=0.016300 mae=0.101800 mse=0.016300 rmse=0.016300 r2=0.246900 
测试集 timing_ctrl: loss=0.026000 mae=0.148500 mse=0.026000 rmse=0.026000 r2=0.180000 
测试集 array_128_32_8t: loss=0.013200 mae=0.086300 mse=0.013200 rmse=0.013200 r2=0.346800 

Epoch 47/200 - 训练: loss=0.014100 mae=0.088900 mse=0.014100 rmse=0.014100 r2=0.356400 
Epoch 47/200 - 验证: loss=0.015200 mae=0.095900 mse=0.015200 rmse=0.015200 r2=0.286800 
Epoch 48/200 - 训练: loss=0.014200 mae=0.089100 mse=0.014200 rmse=0.014200 r2=0.354000 
Epoch 48/200 - 验证: loss=0.014000 mae=0.089900 mse=0.014000 rmse=0.014000 r2=0.340800 
【新的最佳模型！】Epoch 48
测试集 digtime: loss=0.016000 mae=0.099900 mse=0.016000 rmse=0.016000 r2=0.263900 
测试集 timing_ctrl: loss=0.024700 mae=0.143900 mse=0.024700 rmse=0.024700 r2=0.220900 
测试集 array_128_32_8t: loss=0.012700 mae=0.083400 mse=0.012700 rmse=0.012700 r2=0.368600 

Epoch 49/200 - 训练: loss=0.014000 mae=0.087900 mse=0.014000 rmse=0.014000 r2=0.360700 
Epoch 49/200 - 验证: loss=0.015100 mae=0.095500 mse=0.015100 rmse=0.015100 r2=0.289700 
Epoch 50/200 - 训练: loss=0.014000 mae=0.088100 mse=0.014000 rmse=0.014000 r2=0.364800 
Epoch 50/200 - 验证: loss=0.014300 mae=0.090800 mse=0.014300 rmse=0.014300 r2=0.326100 
Epoch 51/200 - 训练: loss=0.014000 mae=0.088100 mse=0.014000 rmse=0.014000 r2=0.362400 
Epoch 51/200 - 验证: loss=0.014700 mae=0.093100 mse=0.014700 rmse=0.014700 r2=0.309900 
Epoch 52/200 - 训练: loss=0.014000 mae=0.087800 mse=0.014000 rmse=0.014000 r2=0.362100 
Epoch 52/200 - 验证: loss=0.015100 mae=0.095700 mse=0.015100 rmse=0.015100 r2=0.290000 
Epoch 53/200 - 训练: loss=0.014000 mae=0.088000 mse=0.014000 rmse=0.014000 r2=0.363500 
Epoch 53/200 - 验证: loss=0.015600 mae=0.097200 mse=0.015600 rmse=0.015600 r2=0.264700 
Epoch 54/200 - 训练: loss=0.014000 mae=0.088000 mse=0.014000 rmse=0.014000 r2=0.364500 
Epoch 54/200 - 验证: loss=0.015800 mae=0.099000 mse=0.015800 rmse=0.015800 r2=0.255700 
Epoch 55/200 - 训练: loss=0.013800 mae=0.087500 mse=0.013800 rmse=0.013800 r2=0.370800 
Epoch 55/200 - 验证: loss=0.015200 mae=0.095100 mse=0.015200 rmse=0.015200 r2=0.285000 
Epoch 56/200 - 训练: loss=0.013900 mae=0.087200 mse=0.013900 rmse=0.013900 r2=0.368400 
Epoch 56/200 - 验证: loss=0.014300 mae=0.091200 mse=0.014300 rmse=0.014300 r2=0.328800 
Epoch 57/200 - 训练: loss=0.013700 mae=0.087100 mse=0.013700 rmse=0.013700 r2=0.375900 
Epoch 57/200 - 验证: loss=0.014100 mae=0.090400 mse=0.014100 rmse=0.014100 r2=0.335900 
Epoch 58/200 - 训练: loss=0.013800 mae=0.086900 mse=0.013800 rmse=0.013800 r2=0.371900 
Epoch 58/200 - 验证: loss=0.015200 mae=0.095300 mse=0.015200 rmse=0.015200 r2=0.283200 
Epoch 59/200 - 训练: loss=0.013600 mae=0.086200 mse=0.013600 rmse=0.013600 r2=0.382200 
Epoch 59/200 - 验证: loss=0.015000 mae=0.095000 mse=0.015000 rmse=0.015000 r2=0.292300 
Epoch 60/200 - 训练: loss=0.013600 mae=0.086400 mse=0.013600 rmse=0.013600 r2=0.380600 
Epoch 60/200 - 验证: loss=0.014500 mae=0.092400 mse=0.014500 rmse=0.014500 r2=0.315300 
Epoch 61/200 - 训练: loss=0.013600 mae=0.086300 mse=0.013600 rmse=0.013600 r2=0.379100 
Epoch 61/200 - 验证: loss=0.014500 mae=0.092500 mse=0.014500 rmse=0.014500 r2=0.315500 
Epoch 62/200 - 训练: loss=0.013500 mae=0.085900 mse=0.013500 rmse=0.013500 r2=0.386200 
Epoch 62/200 - 验证: loss=0.014900 mae=0.093400 mse=0.014900 rmse=0.014900 r2=0.297800 
Epoch 63/200 - 训练: loss=0.013400 mae=0.085200 mse=0.013400 rmse=0.013400 r2=0.389400 
Epoch 63/200 - 验证: loss=0.014200 mae=0.090000 mse=0.014200 rmse=0.014200 r2=0.331300 
Epoch 64/200 - 训练: loss=0.013500 mae=0.085700 mse=0.013500 rmse=0.013500 r2=0.383800 
Epoch 64/200 - 验证: loss=0.014100 mae=0.089900 mse=0.014100 rmse=0.014100 r2=0.338400 
Epoch 65/200 - 训练: loss=0.013500 mae=0.085500 mse=0.013500 rmse=0.013500 r2=0.387100 
Epoch 65/200 - 验证: loss=0.014600 mae=0.093600 mse=0.014600 rmse=0.014600 r2=0.314300 
Epoch 66/200 - 训练: loss=0.013400 mae=0.085100 mse=0.013400 rmse=0.013400 r2=0.391000 
Epoch 66/200 - 验证: loss=0.015100 mae=0.096500 mse=0.015100 rmse=0.015100 r2=0.288500 
Epoch 67/200 - 训练: loss=0.013400 mae=0.085600 mse=0.013400 rmse=0.013400 r2=0.389500 
Epoch 67/200 - 验证: loss=0.014700 mae=0.093300 mse=0.014700 rmse=0.014700 r2=0.309100 
Epoch 68/200 - 训练: loss=0.013200 mae=0.084600 mse=0.013200 rmse=0.013200 r2=0.397200 
Epoch 68/200 - 验证: loss=0.014700 mae=0.095200 mse=0.014700 rmse=0.014700 r2=0.308500 
Epoch 69/200 - 训练: loss=0.013300 mae=0.085100 mse=0.013300 rmse=0.013300 r2=0.393200 
Epoch 69/200 - 验证: loss=0.015000 mae=0.096900 mse=0.015000 rmse=0.015000 r2=0.294000 
Epoch 70/200 - 训练: loss=0.013300 mae=0.084700 mse=0.013300 rmse=0.013300 r2=0.396800 
Epoch 70/200 - 验证: loss=0.015400 mae=0.098300 mse=0.015400 rmse=0.015400 r2=0.277000 
Epoch 71/200 - 训练: loss=0.013200 mae=0.084500 mse=0.013200 rmse=0.013200 r2=0.397700 
Epoch 71/200 - 验证: loss=0.016000 mae=0.102300 mse=0.016000 rmse=0.016000 r2=0.246300 
Epoch 72/200 - 训练: loss=0.013300 mae=0.084600 mse=0.013300 rmse=0.013300 r2=0.396300 
Epoch 72/200 - 验证: loss=0.016100 mae=0.102700 mse=0.016100 rmse=0.016100 r2=0.241500 
Epoch 73/200 - 训练: loss=0.013200 mae=0.084200 mse=0.013200 rmse=0.013200 r2=0.401000 
Epoch 73/200 - 验证: loss=0.015600 mae=0.100200 mse=0.015600 rmse=0.015600 r2=0.266500 
Epoch 74/200 - 训练: loss=0.013200 mae=0.084200 mse=0.013200 rmse=0.013200 r2=0.399000 
Epoch 74/200 - 验证: loss=0.014900 mae=0.096400 mse=0.014900 rmse=0.014900 r2=0.299400 
Epoch 75/200 - 训练: loss=0.013200 mae=0.084300 mse=0.013200 rmse=0.013200 r2=0.400000 
Epoch 75/200 - 验证: loss=0.015600 mae=0.100400 mse=0.015600 rmse=0.015600 r2=0.267800 
Epoch 76/200 - 训练: loss=0.013100 mae=0.083800 mse=0.013100 rmse=0.013100 r2=0.403600 
Epoch 76/200 - 验证: loss=0.015500 mae=0.099400 mse=0.015500 rmse=0.015500 r2=0.271800 
Epoch 77/200 - 训练: loss=0.013100 mae=0.084000 mse=0.013100 rmse=0.013100 r2=0.401400 
Epoch 77/200 - 验证: loss=0.015100 mae=0.097900 mse=0.015100 rmse=0.015100 r2=0.287200 
Epoch 78/200 - 训练: loss=0.013200 mae=0.084000 mse=0.013200 rmse=0.013200 r2=0.400000 
Epoch 78/200 - 验证: loss=0.015100 mae=0.097600 mse=0.015100 rmse=0.015100 r2=0.289600 
Epoch 79/200 - 训练: loss=0.013100 mae=0.083700 mse=0.013100 rmse=0.013100 r2=0.404800 
Epoch 79/200 - 验证: loss=0.016000 mae=0.103000 mse=0.016000 rmse=0.016000 r2=0.246100 
Epoch 80/200 - 训练: loss=0.013100 mae=0.083700 mse=0.013100 rmse=0.013100 r2=0.403100 
Epoch 80/200 - 验证: loss=0.015200 mae=0.097800 mse=0.015200 rmse=0.015200 r2=0.285700 
Epoch 81/200 - 训练: loss=0.013100 mae=0.083600 mse=0.013100 rmse=0.013100 r2=0.405100 
Epoch 81/200 - 验证: loss=0.014600 mae=0.094100 mse=0.014600 rmse=0.014600 r2=0.314600 
Epoch 82/200 - 训练: loss=0.013100 mae=0.083700 mse=0.013100 rmse=0.013100 r2=0.404400 
Epoch 82/200 - 验证: loss=0.015200 mae=0.098500 mse=0.015200 rmse=0.015200 r2=0.284500 
Epoch 83/200 - 训练: loss=0.013100 mae=0.083700 mse=0.013100 rmse=0.013100 r2=0.405100 
Epoch 83/200 - 验证: loss=0.015000 mae=0.097000 mse=0.015000 rmse=0.015000 r2=0.294300 
Epoch 84/200 - 训练: loss=0.013000 mae=0.083300 mse=0.013000 rmse=0.013000 r2=0.408300 
Epoch 84/200 - 验证: loss=0.014700 mae=0.095900 mse=0.014700 rmse=0.014700 r2=0.305800 
Epoch 85/200 - 训练: loss=0.013000 mae=0.083100 mse=0.013000 rmse=0.013000 r2=0.407700 
Epoch 85/200 - 验证: loss=0.014400 mae=0.093000 mse=0.014400 rmse=0.014400 r2=0.324000 
Epoch 86/200 - 训练: loss=0.013000 mae=0.083300 mse=0.013000 rmse=0.013000 r2=0.409700 
Epoch 86/200 - 验证: loss=0.014400 mae=0.092700 mse=0.014400 rmse=0.014400 r2=0.322500 
Epoch 87/200 - 训练: loss=0.013000 mae=0.083300 mse=0.013000 rmse=0.013000 r2=0.407200 
Epoch 87/200 - 验证: loss=0.014900 mae=0.096400 mse=0.014900 rmse=0.014900 r2=0.298200 
Epoch 88/200 - 训练: loss=0.013000 mae=0.083300 mse=0.013000 rmse=0.013000 r2=0.407400 
Epoch 88/200 - 验证: loss=0.015700 mae=0.100300 mse=0.015700 rmse=0.015700 r2=0.259700 
Epoch 89/200 - 训练: loss=0.013000 mae=0.083300 mse=0.013000 rmse=0.013000 r2=0.409900 
Epoch 89/200 - 验证: loss=0.015900 mae=0.101700 mse=0.015900 rmse=0.015900 r2=0.250800 
Epoch 90/200 - 训练: loss=0.012900 mae=0.083100 mse=0.012900 rmse=0.012900 r2=0.410900 
Epoch 90/200 - 验证: loss=0.015900 mae=0.101300 mse=0.015900 rmse=0.015900 r2=0.252600 
Epoch 91/200 - 训练: loss=0.012900 mae=0.083000 mse=0.012900 rmse=0.012900 r2=0.411000 
Epoch 91/200 - 验证: loss=0.014700 mae=0.094500 mse=0.014700 rmse=0.014700 r2=0.306300 
Epoch 92/200 - 训练: loss=0.012900 mae=0.083000 mse=0.012900 rmse=0.012900 r2=0.411300 
Epoch 92/200 - 验证: loss=0.015100 mae=0.097300 mse=0.015100 rmse=0.015100 r2=0.290200 
Epoch 93/200 - 训练: loss=0.013000 mae=0.083200 mse=0.013000 rmse=0.013000 r2=0.409900 
Epoch 93/200 - 验证: loss=0.014700 mae=0.094900 mse=0.014700 rmse=0.014700 r2=0.310200 
Epoch 94/200 - 训练: loss=0.012900 mae=0.083000 mse=0.012900 rmse=0.012900 r2=0.411100 
Epoch 94/200 - 验证: loss=0.015700 mae=0.100800 mse=0.015700 rmse=0.015700 r2=0.261900 
Epoch 95/200 - 训练: loss=0.012900 mae=0.083000 mse=0.012900 rmse=0.012900 r2=0.410500 
Epoch 95/200 - 验证: loss=0.015700 mae=0.100700 mse=0.015700 rmse=0.015700 r2=0.260500 
Epoch 96/200 - 训练: loss=0.012900 mae=0.083100 mse=0.012900 rmse=0.012900 r2=0.411300 
Epoch 96/200 - 验证: loss=0.016400 mae=0.104400 mse=0.016400 rmse=0.016400 r2=0.230000 
Epoch 97/200 - 训练: loss=0.013000 mae=0.083200 mse=0.013000 rmse=0.013000 r2=0.407800 
Epoch 97/200 - 验证: loss=0.015300 mae=0.098600 mse=0.015300 rmse=0.015300 r2=0.279900 
Epoch 98/200 - 训练: loss=0.012800 mae=0.082500 mse=0.012800 rmse=0.012800 r2=0.416300 
Epoch 98/200 - 验证: loss=0.015100 mae=0.097600 mse=0.015100 rmse=0.015100 r2=0.288000 
Epoch 99/200 - 训练: loss=0.013000 mae=0.082900 mse=0.013000 rmse=0.013000 r2=0.409900 
Epoch 99/200 - 验证: loss=0.014900 mae=0.096900 mse=0.014900 rmse=0.014900 r2=0.296700 
Epoch 100/200 - 训练: loss=0.012900 mae=0.082900 mse=0.012900 rmse=0.012900 r2=0.413900 
Epoch 100/200 - 验证: loss=0.014900 mae=0.097200 mse=0.014900 rmse=0.014900 r2=0.296400 
Epoch 101/200 - 训练: loss=0.012900 mae=0.082900 mse=0.012900 rmse=0.012900 r2=0.413500 
Epoch 101/200 - 验证: loss=0.015800 mae=0.101700 mse=0.015800 rmse=0.015800 r2=0.256800 
Epoch 102/200 - 训练: loss=0.012800 mae=0.082400 mse=0.012800 rmse=0.012800 r2=0.418800 
Epoch 102/200 - 验证: loss=0.015000 mae=0.097800 mse=0.015000 rmse=0.015000 r2=0.293100 
Epoch 103/200 - 训练: loss=0.012900 mae=0.082900 mse=0.012900 rmse=0.012900 r2=0.411900 
Epoch 103/200 - 验证: loss=0.015100 mae=0.097800 mse=0.015100 rmse=0.015100 r2=0.289200 
Epoch 104/200 - 训练: loss=0.012900 mae=0.082700 mse=0.012900 rmse=0.012900 r2=0.414000 
Epoch 104/200 - 验证: loss=0.015900 mae=0.102400 mse=0.015900 rmse=0.015900 r2=0.252300 
Epoch 105/200 - 训练: loss=0.012800 mae=0.082600 mse=0.012800 rmse=0.012800 r2=0.415000 
Epoch 105/200 - 验证: loss=0.015400 mae=0.099700 mse=0.015400 rmse=0.015400 r2=0.275400 
Epoch 106/200 - 训练: loss=0.012900 mae=0.082800 mse=0.012900 rmse=0.012900 r2=0.414000 
Epoch 106/200 - 验证: loss=0.015300 mae=0.098900 mse=0.015300 rmse=0.015300 r2=0.282100 
Epoch 107/200 - 训练: loss=0.012800 mae=0.082900 mse=0.012800 rmse=0.012800 r2=0.415800 
Epoch 107/200 - 验证: loss=0.014900 mae=0.097300 mse=0.014900 rmse=0.014900 r2=0.296400 
Epoch 108/200 - 训练: loss=0.012800 mae=0.082400 mse=0.012800 rmse=0.012800 r2=0.417000 
Epoch 108/200 - 验证: loss=0.014800 mae=0.096300 mse=0.014800 rmse=0.014800 r2=0.303400 
Epoch 109/200 - 训练: loss=0.012800 mae=0.082600 mse=0.012800 rmse=0.012800 r2=0.417900 
Epoch 109/200 - 验证: loss=0.015000 mae=0.097800 mse=0.015000 rmse=0.015000 r2=0.291800 
Epoch 110/200 - 训练: loss=0.012800 mae=0.082400 mse=0.012800 rmse=0.012800 r2=0.416800 
Epoch 110/200 - 验证: loss=0.015300 mae=0.098800 mse=0.015300 rmse=0.015300 r2=0.280600 
Epoch 111/200 - 训练: loss=0.012800 mae=0.082400 mse=0.012800 rmse=0.012800 r2=0.417600 
Epoch 111/200 - 验证: loss=0.015500 mae=0.100200 mse=0.015500 rmse=0.015500 r2=0.270000 
Epoch 112/200 - 训练: loss=0.012800 mae=0.082300 mse=0.012800 rmse=0.012800 r2=0.419400 
Epoch 112/200 - 验证: loss=0.015400 mae=0.099800 mse=0.015400 rmse=0.015400 r2=0.273600 
Epoch 113/200 - 训练: loss=0.012700 mae=0.082200 mse=0.012700 rmse=0.012700 r2=0.421500 
Epoch 113/200 - 验证: loss=0.014500 mae=0.094000 mse=0.014500 rmse=0.014500 r2=0.316300 
Epoch 114/200 - 训练: loss=0.012700 mae=0.082400 mse=0.012700 rmse=0.012700 r2=0.420900 
Epoch 114/200 - 验证: loss=0.014900 mae=0.096400 mse=0.014900 rmse=0.014900 r2=0.299600 
Epoch 115/200 - 训练: loss=0.012800 mae=0.082400 mse=0.012800 rmse=0.012800 r2=0.417200 
Epoch 115/200 - 验证: loss=0.016000 mae=0.103500 mse=0.016000 rmse=0.016000 r2=0.244800 
Epoch 116/200 - 训练: loss=0.012800 mae=0.082500 mse=0.012800 rmse=0.012800 r2=0.418000 
Epoch 116/200 - 验证: loss=0.015300 mae=0.099700 mse=0.015300 rmse=0.015300 r2=0.278300 
Epoch 117/200 - 训练: loss=0.012700 mae=0.082300 mse=0.012700 rmse=0.012700 r2=0.421300 
Epoch 117/200 - 验证: loss=0.016200 mae=0.104000 mse=0.016200 rmse=0.016200 r2=0.239700 
Epoch 118/200 - 训练: loss=0.012800 mae=0.082700 mse=0.012800 rmse=0.012800 r2=0.416600 
Epoch 118/200 - 验证: loss=0.015800 mae=0.101600 mse=0.015800 rmse=0.015800 r2=0.254000 
Epoch 119/200 - 训练: loss=0.012700 mae=0.082200 mse=0.012700 rmse=0.012700 r2=0.419600 
Epoch 119/200 - 验证: loss=0.015600 mae=0.101200 mse=0.015600 rmse=0.015600 r2=0.265600 
Epoch 120/200 - 训练: loss=0.012700 mae=0.082200 mse=0.012700 rmse=0.012700 r2=0.421500 
Epoch 120/200 - 验证: loss=0.015600 mae=0.101200 mse=0.015600 rmse=0.015600 r2=0.264100 
Epoch 121/200 - 训练: loss=0.012800 mae=0.082300 mse=0.012800 rmse=0.012800 r2=0.419000 
Epoch 121/200 - 验证: loss=0.015700 mae=0.101700 mse=0.015700 rmse=0.015700 r2=0.259000 
Epoch 122/200 - 训练: loss=0.012700 mae=0.081900 mse=0.012700 rmse=0.012700 r2=0.423400 
Epoch 122/200 - 验证: loss=0.015000 mae=0.097600 mse=0.015000 rmse=0.015000 r2=0.296000 
Epoch 123/200 - 训练: loss=0.012800 mae=0.082200 mse=0.012800 rmse=0.012800 r2=0.418800 
Epoch 123/200 - 验证: loss=0.016500 mae=0.104200 mse=0.016500 rmse=0.016500 r2=0.223600 
Epoch 124/200 - 训练: loss=0.012700 mae=0.082000 mse=0.012700 rmse=0.012700 r2=0.421600 
Epoch 124/200 - 验证: loss=0.016100 mae=0.103800 mse=0.016100 rmse=0.016100 r2=0.240400 
Epoch 125/200 - 训练: loss=0.012700 mae=0.082000 mse=0.012700 rmse=0.012700 r2=0.421800 
Epoch 125/200 - 验证: loss=0.016000 mae=0.103300 mse=0.016000 rmse=0.016000 r2=0.247400 
Epoch 126/200 - 训练: loss=0.012700 mae=0.082300 mse=0.012700 rmse=0.012700 r2=0.420400 
Epoch 126/200 - 验证: loss=0.015300 mae=0.099900 mse=0.015300 rmse=0.015300 r2=0.278900 
Epoch 127/200 - 训练: loss=0.012700 mae=0.081900 mse=0.012700 rmse=0.012700 r2=0.423400 
Epoch 127/200 - 验证: loss=0.015300 mae=0.099600 mse=0.015300 rmse=0.015300 r2=0.281300 
Epoch 128/200 - 训练: loss=0.012700 mae=0.081800 mse=0.012700 rmse=0.012700 r2=0.422500 
Epoch 128/200 - 验证: loss=0.015400 mae=0.100300 mse=0.015400 rmse=0.015400 r2=0.273100 
Epoch 129/200 - 训练: loss=0.012800 mae=0.082300 mse=0.012800 rmse=0.012800 r2=0.419000 
Epoch 129/200 - 验证: loss=0.015900 mae=0.102600 mse=0.015900 rmse=0.015900 r2=0.250500 
Epoch 130/200 - 训练: loss=0.012800 mae=0.082500 mse=0.012800 rmse=0.012800 r2=0.419100 
Epoch 130/200 - 验证: loss=0.014900 mae=0.097500 mse=0.014900 rmse=0.014900 r2=0.299500 
Epoch 131/200 - 训练: loss=0.012700 mae=0.081800 mse=0.012700 rmse=0.012700 r2=0.422800 
Epoch 131/200 - 验证: loss=0.015800 mae=0.102000 mse=0.015800 rmse=0.015800 r2=0.256200 
Epoch 132/200 - 训练: loss=0.012700 mae=0.081900 mse=0.012700 rmse=0.012700 r2=0.424100 
Epoch 132/200 - 验证: loss=0.015500 mae=0.099600 mse=0.015500 rmse=0.015500 r2=0.272700 
Epoch 133/200 - 训练: loss=0.012600 mae=0.082100 mse=0.012600 rmse=0.012600 r2=0.425000 
Epoch 133/200 - 验证: loss=0.015800 mae=0.101900 mse=0.015800 rmse=0.015800 r2=0.255800 
Epoch 134/200 - 训练: loss=0.012600 mae=0.081800 mse=0.012600 rmse=0.012600 r2=0.425400 
Epoch 134/200 - 验证: loss=0.015300 mae=0.099900 mse=0.015300 rmse=0.015300 r2=0.279400 
Epoch 135/200 - 训练: loss=0.012700 mae=0.082000 mse=0.012700 rmse=0.012700 r2=0.423300 
Epoch 135/200 - 验证: loss=0.016100 mae=0.103500 mse=0.016100 rmse=0.016100 r2=0.242800 
Epoch 136/200 - 训练: loss=0.012700 mae=0.082200 mse=0.012700 rmse=0.012700 r2=0.420000 
Epoch 136/200 - 验证: loss=0.016900 mae=0.107000 mse=0.016900 rmse=0.016900 r2=0.205500 
Epoch 137/200 - 训练: loss=0.012600 mae=0.081700 mse=0.012600 rmse=0.012600 r2=0.426000 
Epoch 137/200 - 验证: loss=0.016000 mae=0.103600 mse=0.016000 rmse=0.016000 r2=0.245400 
Epoch 138/200 - 训练: loss=0.012700 mae=0.082200 mse=0.012700 rmse=0.012700 r2=0.421500 
Epoch 138/200 - 验证: loss=0.015600 mae=0.101100 mse=0.015600 rmse=0.015600 r2=0.263900 
Epoch 139/200 - 训练: loss=0.012700 mae=0.081700 mse=0.012700 rmse=0.012700 r2=0.423700 
Epoch 139/200 - 验证: loss=0.016000 mae=0.103200 mse=0.016000 rmse=0.016000 r2=0.247600 
Epoch 140/200 - 训练: loss=0.012600 mae=0.081800 mse=0.012600 rmse=0.012600 r2=0.425900 
Epoch 140/200 - 验证: loss=0.015500 mae=0.100800 mse=0.015500 rmse=0.015500 r2=0.268300 
Epoch 141/200 - 训练: loss=0.012600 mae=0.081600 mse=0.012600 rmse=0.012600 r2=0.424700 
Epoch 141/200 - 验证: loss=0.015100 mae=0.098800 mse=0.015100 rmse=0.015100 r2=0.287600 
Epoch 142/200 - 训练: loss=0.012700 mae=0.081900 mse=0.012700 rmse=0.012700 r2=0.423500 
Epoch 142/200 - 验证: loss=0.015600 mae=0.101300 mse=0.015600 rmse=0.015600 r2=0.265900 
Epoch 143/200 - 训练: loss=0.012600 mae=0.081600 mse=0.012600 rmse=0.012600 r2=0.426300 
Epoch 143/200 - 验证: loss=0.017100 mae=0.107500 mse=0.017100 rmse=0.017100 r2=0.195500 
Epoch 144/200 - 训练: loss=0.012600 mae=0.081700 mse=0.012600 rmse=0.012600 r2=0.424700 
Epoch 144/200 - 验证: loss=0.017400 mae=0.109500 mse=0.017400 rmse=0.017400 r2=0.180600 
Epoch 145/200 - 训练: loss=0.012600 mae=0.081800 mse=0.012600 rmse=0.012600 r2=0.425100 
Epoch 145/200 - 验证: loss=0.017800 mae=0.110800 mse=0.017800 rmse=0.017800 r2=0.164400 
Epoch 146/200 - 训练: loss=0.012600 mae=0.081900 mse=0.012600 rmse=0.012600 r2=0.424200 
Epoch 146/200 - 验证: loss=0.017600 mae=0.110300 mse=0.017600 rmse=0.017600 r2=0.171100 
Epoch 147/200 - 训练: loss=0.012600 mae=0.081800 mse=0.012600 rmse=0.012600 r2=0.426400 
Epoch 147/200 - 验证: loss=0.016800 mae=0.106500 mse=0.016800 rmse=0.016800 r2=0.211300 
Epoch 148/200 - 训练: loss=0.012600 mae=0.081700 mse=0.012600 rmse=0.012600 r2=0.426200 
Epoch 148/200 - 验证: loss=0.018600 mae=0.114000 mse=0.018600 rmse=0.018600 r2=0.125900 
Epoch 149/200 - 训练: loss=0.012600 mae=0.081600 mse=0.012600 rmse=0.012600 r2=0.424800 
Epoch 149/200 - 验证: loss=0.017900 mae=0.110300 mse=0.017900 rmse=0.017900 r2=0.157100 
Epoch 150/200 - 训练: loss=0.012600 mae=0.081500 mse=0.012600 rmse=0.012600 r2=0.426700 
Epoch 150/200 - 验证: loss=0.017200 mae=0.108600 mse=0.017200 rmse=0.017200 r2=0.190400 
Epoch 151/200 - 训练: loss=0.012500 mae=0.081600 mse=0.012500 rmse=0.012500 r2=0.429200 
Epoch 151/200 - 验证: loss=0.017500 mae=0.109700 mse=0.017500 rmse=0.017500 r2=0.176600 
Epoch 152/200 - 训练: loss=0.012600 mae=0.081800 mse=0.012600 rmse=0.012600 r2=0.426200 
Epoch 152/200 - 验证: loss=0.016900 mae=0.107300 mse=0.016900 rmse=0.016900 r2=0.202400 
Epoch 153/200 - 训练: loss=0.012700 mae=0.081800 mse=0.012700 rmse=0.012700 r2=0.423900 
Epoch 153/200 - 验证: loss=0.017100 mae=0.108300 mse=0.017100 rmse=0.017100 r2=0.194600 
Epoch 154/200 - 训练: loss=0.012600 mae=0.081700 mse=0.012600 rmse=0.012600 r2=0.427800 
Epoch 154/200 - 验证: loss=0.017700 mae=0.110700 mse=0.017700 rmse=0.017700 r2=0.168300 
Epoch 155/200 - 训练: loss=0.012600 mae=0.081700 mse=0.012600 rmse=0.012600 r2=0.427000 
Epoch 155/200 - 验证: loss=0.017500 mae=0.110400 mse=0.017500 rmse=0.017500 r2=0.174700 
Epoch 156/200 - 训练: loss=0.012600 mae=0.081800 mse=0.012600 rmse=0.012600 r2=0.427700 
Epoch 156/200 - 验证: loss=0.018000 mae=0.111800 mse=0.018000 rmse=0.018000 r2=0.154600 
Epoch 157/200 - 训练: loss=0.012600 mae=0.081600 mse=0.012600 rmse=0.012600 r2=0.428600 
Epoch 157/200 - 验证: loss=0.017900 mae=0.111800 mse=0.017900 rmse=0.017900 r2=0.158100 
Epoch 158/200 - 训练: loss=0.012600 mae=0.081600 mse=0.012600 rmse=0.012600 r2=0.426500 
Epoch 158/200 - 验证: loss=0.017700 mae=0.110400 mse=0.017700 rmse=0.017700 r2=0.167800 
Epoch 159/200 - 训练: loss=0.012600 mae=0.081700 mse=0.012600 rmse=0.012600 r2=0.427200 
Epoch 159/200 - 验证: loss=0.018500 mae=0.114800 mse=0.018500 rmse=0.018500 r2=0.128600 
Epoch 160/200 - 训练: loss=0.012500 mae=0.081500 mse=0.012500 rmse=0.012500 r2=0.428900 
Epoch 160/200 - 验证: loss=0.016400 mae=0.105200 mse=0.016400 rmse=0.016400 r2=0.229000 
Epoch 161/200 - 训练: loss=0.012600 mae=0.081600 mse=0.012600 rmse=0.012600 r2=0.425900 
Epoch 161/200 - 验证: loss=0.017400 mae=0.109700 mse=0.017400 rmse=0.017400 r2=0.182100 
Epoch 162/200 - 训练: loss=0.012600 mae=0.081800 mse=0.012600 rmse=0.012600 r2=0.426900 
Epoch 162/200 - 验证: loss=0.018300 mae=0.113500 mse=0.018300 rmse=0.018300 r2=0.138200 
Epoch 163/200 - 训练: loss=0.012500 mae=0.081100 mse=0.012500 rmse=0.012500 r2=0.432500 
Epoch 163/200 - 验证: loss=0.017500 mae=0.110500 mse=0.017500 rmse=0.017500 r2=0.175800 
Epoch 164/200 - 训练: loss=0.012500 mae=0.081400 mse=0.012500 rmse=0.012500 r2=0.428800 
Epoch 164/200 - 验证: loss=0.017300 mae=0.109400 mse=0.017300 rmse=0.017300 r2=0.187900 
Epoch 165/200 - 训练: loss=0.012600 mae=0.081500 mse=0.012600 rmse=0.012600 r2=0.426900 
Epoch 165/200 - 验证: loss=0.017500 mae=0.110300 mse=0.017500 rmse=0.017500 r2=0.175200 
Epoch 166/200 - 训练: loss=0.012500 mae=0.081400 mse=0.012500 rmse=0.012500 r2=0.429600 
Epoch 166/200 - 验证: loss=0.018200 mae=0.113000 mse=0.018200 rmse=0.018200 r2=0.142400 
Epoch 167/200 - 训练: loss=0.012600 mae=0.081400 mse=0.012600 rmse=0.012600 r2=0.428400 
Epoch 167/200 - 验证: loss=0.016900 mae=0.107700 mse=0.016900 rmse=0.016900 r2=0.203500 
Epoch 168/200 - 训练: loss=0.012500 mae=0.081400 mse=0.012500 rmse=0.012500 r2=0.428800 
Epoch 168/200 - 验证: loss=0.017300 mae=0.109200 mse=0.017300 rmse=0.017300 r2=0.187900 
Epoch 169/200 - 训练: loss=0.012600 mae=0.081500 mse=0.012600 rmse=0.012600 r2=0.428500 
Epoch 169/200 - 验证: loss=0.019100 mae=0.117100 mse=0.019100 rmse=0.019100 r2=0.102100 
Epoch 170/200 - 训练: loss=0.012600 mae=0.081300 mse=0.012600 rmse=0.012600 r2=0.428300 
Epoch 170/200 - 验证: loss=0.019300 mae=0.117300 mse=0.019300 rmse=0.019300 r2=0.090200 
Epoch 171/200 - 训练: loss=0.012500 mae=0.081500 mse=0.012500 rmse=0.012500 r2=0.429000 
Epoch 171/200 - 验证: loss=0.018600 mae=0.114100 mse=0.018600 rmse=0.018600 r2=0.123200 
Epoch 172/200 - 训练: loss=0.012500 mae=0.081600 mse=0.012500 rmse=0.012500 r2=0.428800 
Epoch 172/200 - 验证: loss=0.017900 mae=0.111500 mse=0.017900 rmse=0.017900 r2=0.158800 
Epoch 173/200 - 训练: loss=0.012600 mae=0.081600 mse=0.012600 rmse=0.012600 r2=0.427300 
Epoch 173/200 - 验证: loss=0.018700 mae=0.115100 mse=0.018700 rmse=0.018700 r2=0.119400 
Epoch 174/200 - 训练: loss=0.012500 mae=0.081600 mse=0.012500 rmse=0.012500 r2=0.429500 
Epoch 174/200 - 验证: loss=0.016700 mae=0.106600 mse=0.016700 rmse=0.016700 r2=0.212500 
Epoch 175/200 - 训练: loss=0.012500 mae=0.081600 mse=0.012500 rmse=0.012500 r2=0.429000 
Epoch 175/200 - 验证: loss=0.018100 mae=0.112700 mse=0.018100 rmse=0.018100 r2=0.150000 
Epoch 176/200 - 训练: loss=0.012500 mae=0.081400 mse=0.012500 rmse=0.012500 r2=0.429700 
Epoch 176/200 - 验证: loss=0.017900 mae=0.111500 mse=0.017900 rmse=0.017900 r2=0.158700 
Epoch 177/200 - 训练: loss=0.012500 mae=0.081500 mse=0.012500 rmse=0.012500 r2=0.430500 
Epoch 177/200 - 验证: loss=0.017400 mae=0.109500 mse=0.017400 rmse=0.017400 r2=0.182000 
Epoch 178/200 - 训练: loss=0.012500 mae=0.081500 mse=0.012500 rmse=0.012500 r2=0.429200 
Epoch 178/200 - 验证: loss=0.017000 mae=0.107800 mse=0.017000 rmse=0.017000 r2=0.201300 
Epoch 179/200 - 训练: loss=0.012400 mae=0.081100 mse=0.012400 rmse=0.012400 r2=0.433800 
Epoch 179/200 - 验证: loss=0.018700 mae=0.114500 mse=0.018700 rmse=0.018700 r2=0.118000 
Epoch 180/200 - 训练: loss=0.012500 mae=0.081300 mse=0.012500 rmse=0.012500 r2=0.430500 
Epoch 180/200 - 验证: loss=0.018500 mae=0.114000 mse=0.018500 rmse=0.018500 r2=0.128800 
Epoch 181/200 - 训练: loss=0.012500 mae=0.081300 mse=0.012500 rmse=0.012500 r2=0.431200 
Epoch 181/200 - 验证: loss=0.018800 mae=0.114700 mse=0.018800 rmse=0.018800 r2=0.117100 
Epoch 182/200 - 训练: loss=0.012500 mae=0.081100 mse=0.012500 rmse=0.012500 r2=0.432700 
Epoch 182/200 - 验证: loss=0.018100 mae=0.112100 mse=0.018100 rmse=0.018100 r2=0.150300 
Epoch 183/200 - 训练: loss=0.012500 mae=0.081500 mse=0.012500 rmse=0.012500 r2=0.430200 
Epoch 183/200 - 验证: loss=0.015300 mae=0.096500 mse=0.015300 rmse=0.015300 r2=0.282000 
Epoch 184/200 - 训练: loss=0.012600 mae=0.081500 mse=0.012600 rmse=0.012600 r2=0.428400 
Epoch 184/200 - 验证: loss=0.016000 mae=0.102400 mse=0.016000 rmse=0.016000 r2=0.248800 
Epoch 185/200 - 训练: loss=0.012500 mae=0.081400 mse=0.012500 rmse=0.012500 r2=0.432100 
Epoch 185/200 - 验证: loss=0.016900 mae=0.107100 mse=0.016900 rmse=0.016900 r2=0.202400 
Epoch 186/200 - 训练: loss=0.012500 mae=0.081200 mse=0.012500 rmse=0.012500 r2=0.432500 
Epoch 186/200 - 验证: loss=0.016700 mae=0.106600 mse=0.016700 rmse=0.016700 r2=0.214300 
Epoch 187/200 - 训练: loss=0.012500 mae=0.081300 mse=0.012500 rmse=0.012500 r2=0.431400 
Epoch 187/200 - 验证: loss=0.017100 mae=0.108000 mse=0.017100 rmse=0.017100 r2=0.196100 
Epoch 188/200 - 训练: loss=0.012500 mae=0.081300 mse=0.012500 rmse=0.012500 r2=0.429800 
Epoch 188/200 - 验证: loss=0.017700 mae=0.110500 mse=0.017700 rmse=0.017700 r2=0.164800 
Epoch 189/200 - 训练: loss=0.012500 mae=0.081200 mse=0.012500 rmse=0.012500 r2=0.430400 
Epoch 189/200 - 验证: loss=0.016500 mae=0.105000 mse=0.016500 rmse=0.016500 r2=0.224900 
Epoch 190/200 - 训练: loss=0.012500 mae=0.081300 mse=0.012500 rmse=0.012500 r2=0.431300 
Epoch 190/200 - 验证: loss=0.016700 mae=0.105800 mse=0.016700 rmse=0.016700 r2=0.214800 
Epoch 191/200 - 训练: loss=0.012400 mae=0.081000 mse=0.012400 rmse=0.012400 r2=0.434800 
Epoch 191/200 - 验证: loss=0.017300 mae=0.108500 mse=0.017300 rmse=0.017300 r2=0.187300 
Epoch 192/200 - 训练: loss=0.012500 mae=0.081300 mse=0.012500 rmse=0.012500 r2=0.432100 
Epoch 192/200 - 验证: loss=0.019400 mae=0.116700 mse=0.019400 rmse=0.019400 r2=0.085000 
Epoch 193/200 - 训练: loss=0.012500 mae=0.081400 mse=0.012500 rmse=0.012500 r2=0.430800 
Epoch 193/200 - 验证: loss=0.016900 mae=0.107000 mse=0.016900 rmse=0.016900 r2=0.205800 
Epoch 194/200 - 训练: loss=0.012400 mae=0.081000 mse=0.012400 rmse=0.012400 r2=0.434000 
Epoch 194/200 - 验证: loss=0.018300 mae=0.112300 mse=0.018300 rmse=0.018300 r2=0.137900 
Epoch 195/200 - 训练: loss=0.012500 mae=0.081300 mse=0.012500 rmse=0.012500 r2=0.432700 
Epoch 195/200 - 验证: loss=0.017500 mae=0.109400 mse=0.017500 rmse=0.017500 r2=0.177300 
Epoch 196/200 - 训练: loss=0.012500 mae=0.081200 mse=0.012500 rmse=0.012500 r2=0.431300 
Epoch 196/200 - 验证: loss=0.018500 mae=0.114100 mse=0.018500 rmse=0.018500 r2=0.128600 
Epoch 197/200 - 训练: loss=0.012500 mae=0.081300 mse=0.012500 rmse=0.012500 r2=0.432000 
Epoch 197/200 - 验证: loss=0.017400 mae=0.109600 mse=0.017400 rmse=0.017400 r2=0.181100 
Epoch 198/200 - 训练: loss=0.012400 mae=0.080900 mse=0.012400 rmse=0.012400 r2=0.434100 
Epoch 198/200 - 验证: loss=0.018000 mae=0.111800 mse=0.018000 rmse=0.018000 r2=0.152500 
Epoch 199/200 - 训练: loss=0.012400 mae=0.081200 mse=0.012400 rmse=0.012400 r2=0.434100 
Epoch 199/200 - 验证: loss=0.019100 mae=0.115700 mse=0.019100 rmse=0.019100 r2=0.101100 
Epoch 200/200 - 训练: loss=0.012400 mae=0.081200 mse=0.012400 rmse=0.012400 r2=0.433900 
Epoch 200/200 - 验证: loss=0.017600 mae=0.110000 mse=0.017600 rmse=0.017600 r2=0.171800 

训练完成!
最佳模型在第 48 轮, 验证R2 = 0.340800, 验证损失 = 0.014000
